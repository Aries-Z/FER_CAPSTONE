{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aries\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2\n",
    "import pickle\n",
    "import numpy\n",
    "import csv\n",
    "import scipy.misc\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "\n",
    "def load_test_data():\n",
    "    f = open('fer2013.csv')\n",
    "    csv_f = csv.reader(f)\n",
    "    test_set_x =[]\n",
    "    test_set_y =[]\n",
    "    for row in csv_f:  \n",
    "        if str(row[2]) == \"PrivateTest\":\n",
    "            test_set_y.append(int(row[0]))\n",
    "            temp_list = []\n",
    "            for pixel in row[1].split():\n",
    "                temp_list.append(float(pixel))\n",
    "#             data = Zerocenter_ZCA_whitening_Global_Contrast_Normalize(temp_list)\n",
    "            test_set_x.append(temp_list)\n",
    "    return test_set_x,test_set_y\n",
    "\n",
    "def load_data():\n",
    "\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    val_x =[]\n",
    "    val_y =[]\n",
    "\n",
    "    with open(\"badtrainingdata.txt\", \"r\") as text:\n",
    "        ToBeRemovedTrainingData = []\n",
    "        for line in text:\n",
    "            ToBeRemovedTrainingData.append(int(line))\n",
    "    number = 0\n",
    "\n",
    "    f = open('fer2013.csv')\n",
    "    csv_f = csv.reader(f)\n",
    "\n",
    "    for row in csv_f:   \n",
    "        number+= 1\n",
    "        if number not in ToBeRemovedTrainingData:\n",
    "\n",
    "            if str(row[2]) == \"Training\" or str(row[2]) == \"PublicTest\" :\n",
    "                temp_list = []\n",
    "\n",
    "                for pixel in row[1].split( ):\n",
    "                    temp_list.append(float(pixel))\n",
    "\n",
    "                train_y.append(int(row[0]))\n",
    "                train_x.append(temp_list)\n",
    "\n",
    "            elif str(row[2]) == \"PrivateTest\":\n",
    "                temp_list = []\n",
    "\n",
    "                for pixel in row[1].split( ):\n",
    "                    temp_list.append(float(pixel))\n",
    "                val_y.append(int(row[0]))\n",
    "                val_x.append(temp_list)\n",
    "    print(type(np.array(train_x)))\n",
    "    return np.asarray(train_x),np.asarray(train_y),np.asarray(val_x),np.asarray(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-fc797e42566f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_x' is not defined"
     ]
    }
   ],
   "source": [
    "type(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "train_x,train_y,val_x,val_y=load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "  # MNIST images are 48x48 pixels, and have one color channel\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 48, 48, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 48, 48, 1]\n",
    "  # Output Tensor Shape: [batch_size, 48, 48, 32]\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  # First max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 48, 48, 32]\n",
    "  # Output Tensor Shape: [batch_size, 24, 24, 32]\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2\n",
    "  # Computes 32 features using a 5x5 filter.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 24, 24, 32]\n",
    "  # Output Tensor Shape: [batch_size, 24, 24, 32]\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=32,\n",
    "      kernel_size=[4, 4],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #2\n",
    "  # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 24, 24, 32]\n",
    "  # Output Tensor Shape: [batch_size, 12, 12, 32]\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #3\n",
    "  # Input Tensor Shape: [batch_size, 12, 12, 32]\n",
    "  # Output Tensor Shape: [batch_size, 12 * 12 * 64]\n",
    "    \n",
    "  conv3 = tf.layers.conv2d(\n",
    "      inputs=pool2,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
    "  # Input Tensor Shape: [batch_size, 12, 12, 64]\n",
    "  # Output Tensor Shape: [batch_size, 6 * 6 * 64]\n",
    "    \n",
    "    \n",
    "  pool3_flat = tf.reshape(pool3, [-1, 6 * 6 * 64])\n",
    "\n",
    "  # Dense Layer\n",
    "  # Densely connected layer with 1024 neurons\n",
    "  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  # Output Tensor Shape: [batch_size, 1024]\n",
    "  dense = tf.layers.dense(inputs=pool3_flat, units=3072, activation=tf.nn.relu)\n",
    "\n",
    "  # Add dropout operation; 0.6 probability that element will be kept\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.3, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits layer\n",
    "  # Input Tensor Shape: [batch_size, 1024]\n",
    "  # Output Tensor Shape: [batch_size, 10]\n",
    "  logits = tf.layers.dense(inputs=dropout, units=7)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': 'worker', '_log_step_count_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_num_worker_replicas': 1, '_master': '', '_is_chief': True, '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000022BAA8AB5F8>, '_service': None, '_session_config': None, '_save_checkpoints_secs': 600, '_tf_random_seed': None, '_save_summary_steps': 100, '_task_id': 0, '_model_dir': '/tmp/mnist_convnet_model', '_evaluation_master': '', '_train_distribute': None, '_save_checkpoints_steps': None, '_global_id_in_cluster': 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create the Estimator\n",
    "fer_classifier = tf.estimator.Estimator(\n",
    "  model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "# Set up logging for predictions\n",
    "# Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log, every_n_iter=500)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model\\model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 30001 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.09775156 0.00017889 0.01076097 0.0681804  0.60547835 0.00664485\n",
      "  0.21100498]\n",
      " [0.00577523 0.00001796 0.0681751  0.0008312  0.92364106 0.00054427\n",
      "  0.00101517]\n",
      " [0.01912992 0.00066629 0.03090848 0.64046696 0.27658665 0.00419897\n",
      "  0.02804274]\n",
      " [0.00227643 0.00017975 0.16167529 0.05225417 0.09098947 0.00068365\n",
      "  0.69194124]\n",
      " [0.00013113 0.00000081 0.00200591 0.0000005  0.0000087  0.99784508\n",
      "  0.00000787]\n",
      " [0.01173509 0.00004353 0.98493572 0.00013198 0.00213252 0.00000051\n",
      "  0.00102065]\n",
      " [0.36653815 0.00101597 0.02890207 0.00465973 0.25872185 0.02272082\n",
      "  0.31744141]\n",
      " [0.02023749 0.00253221 0.00508202 0.1353181  0.00055988 0.76646504\n",
      "  0.06980526]\n",
      " [0.24477305 0.00037505 0.02737873 0.3929989  0.25319483 0.00174572\n",
      "  0.07953372]\n",
      " [0.00717    0.00061115 0.02245014 0.00207691 0.00735781 0.03790645\n",
      "  0.92242754]\n",
      " [0.08398167 0.00004715 0.30072279 0.00007492 0.55812263 0.0002085\n",
      "  0.05684235]\n",
      " [0.00877154 0.00000111 0.00164428 0.97282574 0.00711032 0.0000007\n",
      "  0.00964631]\n",
      " [0.01135526 0.00078186 0.27470645 0.00460977 0.06530328 0.0029129\n",
      "  0.64033048]\n",
      " [0.00087053 0.00054371 0.15589542 0.23814247 0.54394881 0.006121\n",
      "  0.05447806]\n",
      " [0.10049703 0.00035278 0.03888426 0.45404766 0.29176938 0.00083076\n",
      "  0.11361813]\n",
      " [0.05373621 0.00043285 0.63274793 0.04265391 0.10804521 0.00322833\n",
      "  0.15915555]\n",
      " [0.00004369 0.00000236 0.13599648 0.00044802 0.00003483 0.86240182\n",
      "  0.00107279]\n",
      " [0.00000064 0.00000018 0.00232108 0.00000058 0.00002751 0.99764593\n",
      "  0.00000407]\n",
      " [0.01192489 0.00005497 0.01449377 0.00043906 0.00454922 0.00072646\n",
      "  0.96781163]\n",
      " [0.03746525 0.01308511 0.00426822 0.00090438 0.0053512  0.0001952\n",
      "  0.93873064]\n",
      " [0.08080773 0.00066742 0.83708181 0.00937127 0.06650429 0.00006226\n",
      "  0.00550521]\n",
      " [0.06147547 0.00087737 0.10190816 0.00819424 0.07130388 0.15747208\n",
      "  0.59876879]\n",
      " [0.93338862 0.0001799  0.02434203 0.03434711 0.00625091 0.00053619\n",
      "  0.00095524]\n",
      " [0.00001283 0.0000076  0.10214509 0.00114849 0.00003278 0.89658393\n",
      "  0.00006928]\n",
      " [0.06579584 0.16350429 0.60750178 0.06422651 0.0714795  0.00283721\n",
      "  0.02465487]\n",
      " [0.01581568 0.00194909 0.51645013 0.00731419 0.01016428 0.08618836\n",
      "  0.36211827]\n",
      " [0.25052292 0.00599409 0.68559082 0.00748246 0.02662078 0.01177271\n",
      "  0.01201623]\n",
      " [0.00803282 0.00006593 0.74112408 0.06818797 0.04551278 0.11665461\n",
      "  0.02042182]\n",
      " [0.00138249 0.00011132 0.00453319 0.3517092  0.62601165 0.00201962\n",
      "  0.01423252]\n",
      " [0.00548271 0.00064165 0.07934429 0.00146648 0.00048564 0.91215199\n",
      "  0.00042725]\n",
      " [0.00979555 0.01925265 0.27835717 0.03323357 0.10549665 0.12603488\n",
      "  0.42782954]\n",
      " [0.00003753 0.0000024  0.00035239 0.99363987 0.00020744 0.00549295\n",
      "  0.00026741]\n",
      " [0.08155567 0.0003497  0.05992492 0.06888536 0.04395486 0.00248731\n",
      "  0.74284218]\n",
      " [0.01053574 0.00018975 0.84952518 0.04634976 0.0402663  0.00038582\n",
      "  0.05274744]\n",
      " [0.16390351 0.00023165 0.00233748 0.00233277 0.01942177 0.00158704\n",
      "  0.81018578]\n",
      " [0.0693065  0.01747707 0.06287897 0.52025097 0.18568146 0.00218897\n",
      "  0.14221605]\n",
      " [0.02073026 0.00027371 0.01440676 0.76732029 0.02982368 0.00198351\n",
      "  0.16546179]\n",
      " [0.30341204 0.00203696 0.50291411 0.02447716 0.15153163 0.00493769\n",
      "  0.01069041]\n",
      " [0.00417198 0.00032244 0.00513888 0.98175176 0.00567615 0.00070674\n",
      "  0.00223203]\n",
      " [0.00003159 0.00000151 0.00009349 0.99955781 0.00006822 0.00007988\n",
      "  0.00016751]\n",
      " [0.00313188 0.00002319 0.57512213 0.35309628 0.00352007 0.06352312\n",
      "  0.00158333]\n",
      " [0.01369492 0.00086321 0.0258469  0.92527006 0.03021196 0.00158795\n",
      "  0.002525  ]\n",
      " [0.00044013 0.00024925 0.00295029 0.95944606 0.01866627 0.00005236\n",
      "  0.01819564]\n",
      " [0.73100848 0.00036181 0.0961689  0.13190661 0.0159042  0.02071842\n",
      "  0.00393157]\n",
      " [0.15888612 0.00000032 0.48240962 0.00272864 0.34839048 0.00018201\n",
      "  0.00740281]\n",
      " [0.00000001 0.00000039 0.00328467 0.00000003 0.00006201 0.99665116\n",
      "  0.00000173]\n",
      " [0.04402184 0.00140596 0.72753757 0.0233347  0.0175361  0.16817042\n",
      "  0.0179934 ]\n",
      " [0.09503519 0.00896801 0.01265347 0.18885409 0.57780363 0.00356299\n",
      "  0.11312262]\n",
      " [0.12210993 0.11683114 0.24028688 0.40254017 0.05683831 0.00020043\n",
      "  0.06119314]\n",
      " [0.04217264 0.00060953 0.35883075 0.06173171 0.5101572  0.00059515\n",
      "  0.02590302]]\n",
      "INFO:tensorflow:loss = 0.579860508441925, step = 30000\n",
      "INFO:tensorflow:global_step/sec: 6.0021\n",
      "INFO:tensorflow:loss = 0.5632078647613525, step = 30100 (16.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05728\n",
      "INFO:tensorflow:loss = 0.6071534156799316, step = 30200 (16.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.07301\n",
      "INFO:tensorflow:loss = 0.6536517143249512, step = 30300 (16.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02188\n",
      "INFO:tensorflow:loss = 0.7695924043655396, step = 30400 (16.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.00721\n",
      "INFO:tensorflow:probabilities = [[0.00407784 0.00220073 0.00026834 0.96335506 0.00312833 0.00146486\n",
      "  0.02550484]\n",
      " [0.24027496 0.00013587 0.30741753 0.00046166 0.14787661 0.00020029\n",
      "  0.30363307]\n",
      " [0.21404171 0.14158463 0.21723083 0.00389433 0.31085599 0.01182002\n",
      "  0.10057248]\n",
      " [0.0792608  0.01684144 0.09939357 0.05373618 0.32551318 0.02683199\n",
      "  0.39842284]\n",
      " [0.00504004 0.00000125 0.98541518 0.00089397 0.00126457 0.0001348\n",
      "  0.00725018]\n",
      " [0.02506645 0.00027019 0.01396033 0.00055621 0.00402607 0.00098816\n",
      "  0.95513259]\n",
      " [0.05577026 0.00195108 0.11870184 0.05552604 0.00530955 0.76146212\n",
      "  0.00127911]\n",
      " [0.00016081 0.00006411 0.22914919 0.17159184 0.00033783 0.59772232\n",
      "  0.0009739 ]\n",
      " [0.00363919 0.00200906 0.02669182 0.87228347 0.03537273 0.00189748\n",
      "  0.05810626]\n",
      " [0.000542   0.00302786 0.00408957 0.07618545 0.00005239 0.8925648\n",
      "  0.02353792]\n",
      " [0.06805846 0.00105946 0.12651307 0.01421726 0.39197006 0.01918759\n",
      "  0.3789941 ]\n",
      " [0.00004105 0.00000006 0.00021069 0.00001911 0.00054643 0.00000005\n",
      "  0.9991826 ]\n",
      " [0.00167971 0.00020518 0.6468453  0.0272446  0.03990069 0.2655157\n",
      "  0.01860882]\n",
      " [0.0219004  0.00009354 0.01727688 0.91609388 0.02341446 0.00260692\n",
      "  0.01861392]\n",
      " [0.57738318 0.03568687 0.01751116 0.0915585  0.17819117 0.00557896\n",
      "  0.09409016]\n",
      " [0.05176273 0.00175217 0.07001019 0.2733533  0.25989311 0.01005909\n",
      "  0.33316942]\n",
      " [0.00024901 0.00023236 0.00523237 0.52619599 0.01384541 0.00001535\n",
      "  0.4542295 ]\n",
      " [0.66051659 0.00032954 0.01529625 0.16194011 0.09423777 0.00177929\n",
      "  0.06590045]\n",
      " [0.12130084 0.00427354 0.09771353 0.55319882 0.16308653 0.00552143\n",
      "  0.05490531]\n",
      " [0.00503451 0.00074019 0.13208212 0.00537961 0.02797085 0.00025755\n",
      "  0.82853515]\n",
      " [0.21911256 0.00188039 0.00748543 0.0129376  0.14813743 0.00395072\n",
      "  0.60649588]\n",
      " [0.05660903 0.00036569 0.08752391 0.00082171 0.33555258 0.00169632\n",
      "  0.51743076]\n",
      " [0.00098801 0.00000116 0.01578129 0.03880835 0.01848742 0.03346069\n",
      "  0.89247309]\n",
      " [0.10984537 0.02184191 0.14437372 0.09954702 0.58692812 0.00070841\n",
      "  0.03675544]\n",
      " [0.00430345 0.00000069 0.00092171 0.00431521 0.00091204 0.98915553\n",
      "  0.00039137]\n",
      " [0.760235   0.00008216 0.10027609 0.00192919 0.10278731 0.00156754\n",
      "  0.03312271]\n",
      " [0.00620985 0.00050944 0.02633807 0.17851527 0.7602105  0.01922473\n",
      "  0.00899214]\n",
      " [0.10179338 0.00233488 0.00854081 0.86235435 0.00642698 0.0002121\n",
      "  0.01833749]\n",
      " [0.01049331 0.00032114 0.00136945 0.36269551 0.00819734 0.00006833\n",
      "  0.61685492]\n",
      " [0.04952267 0.00019477 0.35846902 0.01259222 0.21904227 0.0895983\n",
      "  0.27058075]\n",
      " [0.1312803  0.01706073 0.08631643 0.04576587 0.08364779 0.01646212\n",
      "  0.61946676]\n",
      " [0.01526371 0.00012673 0.00357996 0.00033285 0.16404568 0.00004718\n",
      "  0.81660389]\n",
      " [0.00103353 0.00041774 0.92365932 0.01410316 0.04175266 0.00377431\n",
      "  0.01525929]\n",
      " [0.14397075 0.00023261 0.14695141 0.03303774 0.12992352 0.00323545\n",
      "  0.54264852]\n",
      " [0.04338383 0.00279699 0.31967627 0.12534278 0.05373009 0.33160486\n",
      "  0.12346518]\n",
      " [0.06816793 0.00741054 0.00491319 0.11749545 0.03583641 0.00034729\n",
      "  0.7658292 ]\n",
      " [0.00038343 0.00006817 0.10361402 0.14713243 0.64144338 0.01034188\n",
      "  0.09701668]\n",
      " [0.08453031 0.00029513 0.00938715 0.00080974 0.02074786 0.00000104\n",
      "  0.88422877]\n",
      " [0.04758241 0.00044768 0.11825233 0.0008655  0.28760344 0.0008878\n",
      "  0.54436085]\n",
      " [0.16653059 0.00146302 0.21398338 0.00523286 0.09135622 0.00744552\n",
      "  0.51398841]\n",
      " [0.0191431  0.00042764 0.11622599 0.00214294 0.43112366 0.01145112\n",
      "  0.41948554]\n",
      " [0.00000141 0.00000002 0.00000058 0.99973603 0.00000066 0.00000001\n",
      "  0.00026128]\n",
      " [0.00862889 0.0001167  0.03025988 0.88449947 0.05689112 0.00260985\n",
      "  0.01699409]\n",
      " [0.02334884 0.00019479 0.02521325 0.00046016 0.92731959 0.00067664\n",
      "  0.02278673]\n",
      " [0.39366098 0.02692343 0.09949582 0.00009717 0.22637022 0.00014698\n",
      "  0.25330539]\n",
      " [0.00433326 0.0000064  0.00077163 0.9777168  0.01168002 0.00000933\n",
      "  0.00548256]\n",
      " [0.00472741 0.00004306 0.00549464 0.95564227 0.00152898 0.00076336\n",
      "  0.03180029]\n",
      " [0.34684442 0.01634257 0.4830442  0.03916095 0.08984631 0.00032061\n",
      "  0.02444095]\n",
      " [0.0391789  0.01860806 0.02486529 0.56678931 0.16854051 0.0290355\n",
      "  0.15298243]\n",
      " [0.1874352  0.02560262 0.37660423 0.00112785 0.09439751 0.00025084\n",
      "  0.31458174]] (82.890 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.9002640247344971, step = 30500 (16.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.00872\n",
      "INFO:tensorflow:loss = 0.7689495086669922, step = 30600 (16.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.01072\n",
      "INFO:tensorflow:loss = 0.48154890537261963, step = 30700 (16.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.01145\n",
      "INFO:tensorflow:loss = 0.5045174360275269, step = 30800 (16.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.01097\n",
      "INFO:tensorflow:loss = 0.5309566259384155, step = 30900 (16.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.00346\n",
      "INFO:tensorflow:probabilities = [[0.87738357 0.00103349 0.02456148 0.04272764 0.01888544 0.00000382\n",
      "  0.03540456]\n",
      " [0.57657561 0.00506366 0.33013037 0.00877611 0.00330061 0.07113443\n",
      "  0.0050192 ]\n",
      " [0.00475179 0.00000683 0.05792422 0.89772454 0.03424728 0.00327439\n",
      "  0.00207095]\n",
      " [0.05489612 0.00117789 0.00063997 0.00039743 0.00298895 0.00004163\n",
      "  0.93985801]\n",
      " [0.6336643  0.00792702 0.03260557 0.06286726 0.23338643 0.02259482\n",
      "  0.00695459]\n",
      " [0.01032437 0.05691703 0.16837863 0.0085671  0.54309171 0.00009642\n",
      "  0.21262474]\n",
      " [0.03328594 0.00003731 0.11487112 0.00080387 0.02580822 0.73667198\n",
      "  0.08852156]\n",
      " [0.00032992 0.00001556 0.02014327 0.00000325 0.00412456 0.97361461\n",
      "  0.00176882]\n",
      " [0.05616597 0.01202343 0.00927069 0.28446929 0.08783795 0.01791923\n",
      "  0.53231344]\n",
      " [0.02956475 0.00184955 0.00737021 0.000389   0.88035832 0.0001286\n",
      "  0.08033957]\n",
      " [0.04021809 0.0406055  0.7890858  0.00441122 0.02395685 0.09022359\n",
      "  0.01149897]\n",
      " [0.0728508  0.01533878 0.04269163 0.19314319 0.08204552 0.02337492\n",
      "  0.57055516]\n",
      " [0.05926552 0.0008014  0.01757126 0.19603759 0.1110468  0.000145\n",
      "  0.61513244]\n",
      " [0.00026769 0.00000076 0.00099402 0.00003022 0.00006592 0.99860153\n",
      "  0.00003985]\n",
      " [0.32160601 0.35168999 0.08848518 0.08587673 0.00655079 0.03924834\n",
      "  0.10654297]\n",
      " [0.04259408 0.00041834 0.44033743 0.44177033 0.05952858 0.00008653\n",
      "  0.01526471]\n",
      " [0.00001743 0.00008138 0.00001111 0.99986322 0.00001648 0.00000511\n",
      "  0.00000527]\n",
      " [0.03387513 0.00065493 0.08261904 0.0418284  0.47158544 0.00025281\n",
      "  0.36918425]\n",
      " [0.23548952 0.01191245 0.17703584 0.05474341 0.50242066 0.00278298\n",
      "  0.01561514]\n",
      " [0.00249868 0.00097242 0.02625223 0.02923913 0.66626259 0.00019513\n",
      "  0.27457983]\n",
      " [0.55480154 0.00002423 0.00536402 0.24073601 0.16956941 0.01451741\n",
      "  0.01498738]\n",
      " [0.05726716 0.0012771  0.12740791 0.32284796 0.08580375 0.01528704\n",
      "  0.39010908]\n",
      " [0.00002238 0.00000031 0.01202342 0.0000089  0.00001324 0.98788807\n",
      "  0.00004368]\n",
      " [0.05274015 0.01180363 0.0394265  0.01427624 0.09328052 0.00678907\n",
      "  0.78168387]\n",
      " [0.00043669 0.00000008 0.00348165 0.03770929 0.00002255 0.95830432\n",
      "  0.00004542]\n",
      " [0.6172115  0.01172464 0.18175312 0.01725587 0.11255213 0.00367112\n",
      "  0.05583162]\n",
      " [0.06166383 0.0000239  0.00129781 0.89921399 0.00056511 0.00105318\n",
      "  0.03618218]\n",
      " [0.00786342 0.00007538 0.03673563 0.41440796 0.53113945 0.00013396\n",
      "  0.0096442 ]\n",
      " [0.96995028 0.00704724 0.01607328 0.00188585 0.00482168 0.00018098\n",
      "  0.00004069]\n",
      " [0.10261889 0.00005722 0.00293815 0.04041852 0.02027375 0.00402236\n",
      "  0.82967112]\n",
      " [0.05643204 0.13447598 0.11799673 0.04418931 0.50421542 0.00015097\n",
      "  0.14253955]\n",
      " [0.00395025 0.0002714  0.00678418 0.06394755 0.33965971 0.00019728\n",
      "  0.58518963]\n",
      " [0.11041094 0.01263188 0.10048658 0.00663987 0.09587037 0.0125316\n",
      "  0.66142876]\n",
      " [0.07189195 0.0058953  0.00679182 0.00068682 0.02142819 0.01784251\n",
      "  0.87546342]\n",
      " [0.03092057 0.00008623 0.04276512 0.00698588 0.01691592 0.89789254\n",
      "  0.00443375]\n",
      " [0.00560751 0.00026032 0.0079719  0.00316538 0.19384931 0.0009379\n",
      "  0.78820768]\n",
      " [0.17676429 0.00668826 0.03295859 0.42917075 0.00427266 0.22731477\n",
      "  0.12283068]\n",
      " [0.11335824 0.00144161 0.0890507  0.47392775 0.12826276 0.00540011\n",
      "  0.18855884]\n",
      " [0.00984233 0.00000012 0.00330525 0.00894604 0.24404434 0.00049497\n",
      "  0.73336695]\n",
      " [0.25111957 0.0000568  0.00130484 0.7335632  0.00140287 0.00021442\n",
      "  0.01233829]\n",
      " [0.22525034 0.12434639 0.16404782 0.12279082 0.19740839 0.02979837\n",
      "  0.13635788]\n",
      " [0.78316028 0.02488978 0.02217435 0.00225783 0.03726337 0.00169899\n",
      "  0.1285554 ]\n",
      " [0.01161165 0.0004287  0.12847525 0.00258938 0.02640639 0.83011702\n",
      "  0.00037162]\n",
      " [0.04242323 0.02326237 0.6838934  0.02232317 0.14896289 0.00046637\n",
      "  0.07866858]\n",
      " [0.26360749 0.00050978 0.06070321 0.49403365 0.02769302 0.00017439\n",
      "  0.15327847]\n",
      " [0.00002099 0.0000038  0.00009942 0.99935059 0.00006134 0.00000792\n",
      "  0.00045595]\n",
      " [0.02868145 0.00361796 0.62556996 0.3401477  0.00096489 0.00084415\n",
      "  0.00017391]\n",
      " [0.00339462 0.00012952 0.0662912  0.00004265 0.00250533 0.92613223\n",
      "  0.00150445]\n",
      " [0.90736402 0.00001952 0.01568993 0.04956438 0.01892884 0.00412154\n",
      "  0.00431177]\n",
      " [0.01295059 0.00142781 0.01510021 0.85240535 0.04625871 0.00198705\n",
      "  0.06987027]] (83.207 sec)\n",
      "INFO:tensorflow:loss = 0.7120338082313538, step = 31000 (16.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.99874\n",
      "INFO:tensorflow:loss = 0.5545505881309509, step = 31100 (16.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03118\n",
      "INFO:tensorflow:loss = 0.6003116369247437, step = 31200 (16.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0445\n",
      "INFO:tensorflow:loss = 0.7871229648590088, step = 31300 (16.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04117\n",
      "INFO:tensorflow:loss = 0.4469769299030304, step = 31400 (16.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04532\n",
      "INFO:tensorflow:probabilities = [[0.29041904 0.0016605  0.22605566 0.40488301 0.0462497  0.00725903\n",
      "  0.02347306]\n",
      " [0.0014195  0.09770306 0.0094977  0.03578373 0.00007527 0.14180055\n",
      "  0.71372021]\n",
      " [0.00000256 0.00000177 0.00001122 0.99994557 0.00001206 0.00000019\n",
      "  0.00002663]\n",
      " [0.3038331  0.00012477 0.38142348 0.27841405 0.01264418 0.02170473\n",
      "  0.00185569]\n",
      " [0.01028445 0.00032436 0.0090304  0.00743942 0.97266639 0.00023158\n",
      "  0.00002342]\n",
      " [0.0117266  0.31300272 0.17044737 0.00028852 0.29713422 0.00006934\n",
      "  0.20733123]\n",
      " [0.00050674 0.0001548  0.00019831 0.99776928 0.00034981 0.00065393\n",
      "  0.00036714]\n",
      " [0.02318754 0.00034838 0.00317688 0.0000463  0.11458237 0.00255047\n",
      "  0.85610805]\n",
      " [0.02113781 0.0106253  0.00330639 0.85867708 0.00236997 0.00092696\n",
      "  0.10295649]\n",
      " [0.51941283 0.00182694 0.07083283 0.00109351 0.21899349 0.02535108\n",
      "  0.16248932]\n",
      " [0.00643936 0.00000389 0.01355569 0.0172154  0.87994921 0.00015086\n",
      "  0.08268559]\n",
      " [0.40637164 0.00422814 0.11421343 0.00015843 0.00902372 0.00198469\n",
      "  0.46401996]\n",
      " [0.7606264  0.00035196 0.03817458 0.07938445 0.12122717 0.00007732\n",
      "  0.00015812]\n",
      " [0.03276553 0.00007178 0.7427781  0.04186845 0.00299928 0.13521826\n",
      "  0.0442986 ]\n",
      " [0.14904032 0.00873707 0.22875487 0.01415227 0.12600818 0.00101777\n",
      "  0.47228952]\n",
      " [0.23406826 0.00003457 0.53481599 0.00005666 0.06395988 0.05747173\n",
      "  0.10959292]\n",
      " [0.02031815 0.00061115 0.00203772 0.95497471 0.00070201 0.00005856\n",
      "  0.0212977 ]\n",
      " [0.00403825 0.00309801 0.01437705 0.01436493 0.81551987 0.14830746\n",
      "  0.00029443]\n",
      " [0.28372431 0.00227603 0.02030554 0.59533374 0.03503143 0.01773789\n",
      "  0.04559106]\n",
      " [0.00448798 0.00005354 0.01264053 0.97952791 0.00062587 0.00017343\n",
      "  0.00249075]\n",
      " [0.0060352  0.00014765 0.03100613 0.09839576 0.02149355 0.00098401\n",
      "  0.84193771]\n",
      " [0.00204087 0.00000974 0.00005386 0.99476588 0.00141029 0.00001721\n",
      "  0.00170215]\n",
      " [0.01782084 0.00050663 0.74582264 0.08463708 0.09413023 0.0072598\n",
      "  0.04982277]\n",
      " [0.00000036 0.         0.15738281 0.         0.00594766 0.83666904\n",
      "  0.00000011]\n",
      " [0.01181522 0.00000272 0.00005904 0.00012952 0.98156959 0.00006858\n",
      "  0.00635532]\n",
      " [0.76466358 0.02187043 0.0496859  0.00258254 0.0016267  0.00543211\n",
      "  0.15413875]\n",
      " [0.00355726 0.00020041 0.03732421 0.00882335 0.93523749 0.01356093\n",
      "  0.00129635]\n",
      " [0.00205227 0.00014663 0.17038137 0.0135341  0.34913754 0.00011704\n",
      "  0.46463105]\n",
      " [0.16476224 0.06934757 0.273045   0.13107943 0.34207669 0.00149296\n",
      "  0.01819611]\n",
      " [0.15344418 0.0129537  0.08784486 0.21690618 0.12012207 0.0321749\n",
      "  0.37655411]\n",
      " [0.0025248  0.0011292  0.00912293 0.18988747 0.04103037 0.00036777\n",
      "  0.75593747]\n",
      " [0.02837372 0.12399836 0.00215441 0.0006183  0.0167077  0.82760513\n",
      "  0.00054239]\n",
      " [0.00000009 0.00000003 0.00000003 0.99999979 0.         0.00000002\n",
      "  0.00000004]\n",
      " [0.00000089 0.00000003 0.00691803 0.00000889 0.00000177 0.99307033\n",
      "  0.00000006]\n",
      " [0.00914392 0.00027273 0.81399731 0.00171406 0.11737081 0.05634542\n",
      "  0.00115575]\n",
      " [0.78520459 0.00000471 0.03014787 0.16573949 0.01158228 0.00002128\n",
      "  0.00729979]\n",
      " [0.00058406 0.00000024 0.9191468  0.00423539 0.07489894 0.00098144\n",
      "  0.00015313]\n",
      " [0.00109572 0.00065194 0.00105383 0.95861011 0.0169486  0.00050968\n",
      "  0.02113012]\n",
      " [0.12157104 0.00076887 0.04636234 0.00431938 0.82433343 0.00102407\n",
      "  0.00162086]\n",
      " [0.00370782 0.00345733 0.04391589 0.39857907 0.07317296 0.0342766\n",
      "  0.44289034]\n",
      " [0.24547773 0.00038304 0.15044863 0.0105517  0.05766613 0.00781426\n",
      "  0.52765851]\n",
      " [0.00065758 0.00000601 0.0001707  0.99415426 0.00010902 0.00000556\n",
      "  0.00489688]\n",
      " [0.12292173 0.002604   0.31817686 0.50836336 0.02926919 0.00152501\n",
      "  0.01713984]\n",
      " [0.31772571 0.02144026 0.19984356 0.05149646 0.07040794 0.26108397\n",
      "  0.0780021 ]\n",
      " [0.00080316 0.000444   0.0128498  0.00000411 0.98430645 0.00026642\n",
      "  0.00132606]\n",
      " [0.0964951  0.00050552 0.0194235  0.00221748 0.62301053 0.00061291\n",
      "  0.25773495]\n",
      " [0.00001344 0.00000106 0.00607659 0.00047024 0.00006884 0.99329359\n",
      "  0.00007625]\n",
      " [0.05258431 0.01955264 0.01227737 0.91281082 0.00144248 0.00009432\n",
      "  0.00123806]\n",
      " [0.00400368 0.0014109  0.00081073 0.01015471 0.00455938 0.04772997\n",
      "  0.93133063]\n",
      " [0.36476629 0.11766122 0.10770106 0.04527489 0.17398171 0.06654908\n",
      "  0.12406575]] (82.890 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6021482944488525, step = 31500 (16.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02579\n",
      "INFO:tensorflow:loss = 0.6192987561225891, step = 31600 (16.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03524\n",
      "INFO:tensorflow:loss = 0.6237355470657349, step = 31700 (16.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0074\n",
      "INFO:tensorflow:loss = 0.5743066072463989, step = 31800 (16.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02742\n",
      "INFO:tensorflow:loss = 0.8978308439254761, step = 31900 (16.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0198\n",
      "INFO:tensorflow:probabilities = [[0.53715838 0.25152693 0.02072411 0.00189972 0.12988311 0.00037589\n",
      "  0.05843186]\n",
      " [0.00000478 0.000002   0.00011711 0.99910412 0.00001032 0.00000788\n",
      "  0.00075379]\n",
      " [0.04804001 0.00075939 0.09988329 0.00458263 0.30512912 0.02348937\n",
      "  0.51811619]\n",
      " [0.12997043 0.02105156 0.72169037 0.00467636 0.02954147 0.00591976\n",
      "  0.08715006]\n",
      " [0.0000097  0.00001116 0.000011   0.99950773 0.00038128 0.00000997\n",
      "  0.00006917]\n",
      " [0.03576819 0.01156209 0.53148129 0.03092833 0.09076449 0.22479762\n",
      "  0.07469799]\n",
      " [0.03270949 0.00009952 0.00432717 0.94549754 0.01251326 0.00013012\n",
      "  0.00472289]\n",
      " [0.00070427 0.00000003 0.00003404 0.99905183 0.00002481 0.00000053\n",
      "  0.0001845 ]\n",
      " [0.30617136 0.00005984 0.00008824 0.07972842 0.61272063 0.00003568\n",
      "  0.00119583]\n",
      " [0.00467383 0.00003118 0.00605054 0.05845153 0.21097207 0.00237921\n",
      "  0.71744163]\n",
      " [0.05893756 0.000783   0.02573492 0.78782816 0.06733936 0.00733508\n",
      "  0.05204193]\n",
      " [0.01175084 0.00891493 0.55621436 0.21640761 0.06645265 0.12504033\n",
      "  0.01521928]\n",
      " [0.01165468 0.00030677 0.00860056 0.00102186 0.31363596 0.00243572\n",
      "  0.66234446]\n",
      " [0.02512348 0.00200425 0.48652112 0.0634996  0.39773454 0.00000695\n",
      "  0.02511005]\n",
      " [0.84402689 0.01730827 0.0473654  0.03006921 0.026478   0.03306722\n",
      "  0.00168501]\n",
      " [0.53777721 0.00119687 0.40899314 0.0001735  0.04886562 0.00073651\n",
      "  0.00225715]\n",
      " [0.1255302  0.00170583 0.69842621 0.00237684 0.0721401  0.05142938\n",
      "  0.04839143]\n",
      " [0.00189397 0.00003826 0.00104213 0.97929389 0.01708282 0.00059181\n",
      "  0.00005711]\n",
      " [0.00006396 0.00128469 0.00445176 0.98683279 0.00551334 0.00017998\n",
      "  0.00167348]\n",
      " [0.01603796 0.00848301 0.01312801 0.87291806 0.07942774 0.00046591\n",
      "  0.00953931]\n",
      " [0.0024409  0.00012295 0.0596075  0.92081061 0.01451162 0.00028372\n",
      "  0.0022227 ]\n",
      " [0.02230518 0.00114348 0.0014901  0.96892877 0.00028399 0.00456382\n",
      "  0.00128466]\n",
      " [0.0000079  0.00000081 0.00033028 0.96435516 0.00024136 0.03471481\n",
      "  0.00034968]\n",
      " [0.03269442 0.00244769 0.40901806 0.00189014 0.49944297 0.00030179\n",
      "  0.05420493]\n",
      " [0.00006704 0.0003401  0.00010261 0.99877679 0.00050998 0.0000462\n",
      "  0.00015728]\n",
      " [0.39149632 0.02841167 0.56206876 0.00000883 0.00188439 0.01540938\n",
      "  0.00072065]\n",
      " [0.29236414 0.00035407 0.37067894 0.06230945 0.08150237 0.04611416\n",
      "  0.14667688]\n",
      " [0.16840105 0.00716788 0.00512505 0.73155378 0.03719853 0.03416751\n",
      "  0.01638621]\n",
      " [0.10822773 0.00454668 0.63859558 0.22761486 0.00046488 0.01323642\n",
      "  0.00731385]\n",
      " [0.00169145 0.00203684 0.88254465 0.04895703 0.00042353 0.00062399\n",
      "  0.06372251]\n",
      " [0.00001132 0.00022083 0.00004509 0.99954657 0.00001563 0.00006034\n",
      "  0.00010022]\n",
      " [0.00062762 0.00000913 0.72230736 0.00025851 0.001304   0.27518496\n",
      "  0.00030843]\n",
      " [0.00015863 0.00003089 0.00364162 0.0003152  0.00604291 0.98971082\n",
      "  0.00009994]\n",
      " [0.00731661 0.00002342 0.92138395 0.00004536 0.02502956 0.03090108\n",
      "  0.01530003]\n",
      " [0.00014882 0.00000075 0.00229553 0.00000948 0.00000318 0.99753819\n",
      "  0.00000405]\n",
      " [0.00322604 0.00000067 0.00007871 0.         0.00360199 0.00000424\n",
      "  0.99308835]\n",
      " [0.00042484 0.00000004 0.00022718 0.99893134 0.00014631 0.00000293\n",
      "  0.00026738]\n",
      " [0.00131483 0.00057656 0.00461852 0.00431052 0.00019587 0.00011335\n",
      "  0.98887035]\n",
      " [0.96767978 0.01349479 0.00839221 0.00008275 0.01016794 0.00017813\n",
      "  0.0000044 ]\n",
      " [0.06424159 0.00008235 0.04425822 0.00256905 0.72543112 0.03768485\n",
      "  0.12573283]\n",
      " [0.00011209 0.00000838 0.00010521 0.99952168 0.00000374 0.00000201\n",
      "  0.00024687]\n",
      " [0.03518526 0.00606491 0.37267839 0.08275968 0.10590643 0.02158904\n",
      "  0.3758163 ]\n",
      " [0.03564793 0.00203494 0.42554085 0.04693675 0.13418479 0.05336147\n",
      "  0.30229326]\n",
      " [0.62508687 0.0000141  0.01044292 0.30934724 0.03444409 0.00080775\n",
      "  0.01985702]\n",
      " [0.99666782 0.00031064 0.00021498 0.00028926 0.00149076 0.00000317\n",
      "  0.00102337]\n",
      " [0.00003389 0.00000079 0.00001125 0.99994891 0.00000053 0.00000019\n",
      "  0.00000445]\n",
      " [0.00022495 0.00006125 0.00063924 0.99645337 0.00092685 0.00009765\n",
      "  0.00159669]\n",
      " [0.00451497 0.00008104 0.04688877 0.00634502 0.11476971 0.01010414\n",
      "  0.81729635]\n",
      " [0.21436634 0.02645526 0.45537889 0.04100253 0.1252547  0.01286949\n",
      "  0.12467279]\n",
      " [0.01205401 0.00001258 0.00162843 0.01778066 0.0293253  0.00015064\n",
      "  0.93904839]] (83.014 sec)\n",
      "INFO:tensorflow:loss = 0.4829319715499878, step = 32000 (16.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.01568\n",
      "INFO:tensorflow:loss = 0.6579694747924805, step = 32100 (16.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.00331\n",
      "INFO:tensorflow:loss = 0.4741683900356293, step = 32200 (16.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0069\n",
      "INFO:tensorflow:loss = 0.6630632877349854, step = 32300 (16.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02069\n",
      "INFO:tensorflow:loss = 0.6014916896820068, step = 32400 (16.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.01285\n",
      "INFO:tensorflow:probabilities = [[0.04286408 0.03632259 0.0078251  0.01542295 0.77035571 0.00294903\n",
      "  0.12426053]\n",
      " [0.1067779  0.00037002 0.00255606 0.0004969  0.31321519 0.00584866\n",
      "  0.57073527]\n",
      " [0.0000156  0.00000009 0.04704191 0.00135912 0.00004634 0.95153278\n",
      "  0.00000416]\n",
      " [0.00003741 0.00000088 0.03217019 0.92723052 0.01887281 0.02158912\n",
      "  0.00009907]\n",
      " [0.01811198 0.00046538 0.09747174 0.00417881 0.1537867  0.09865402\n",
      "  0.62733137]\n",
      " [0.11873989 0.05294929 0.7485892  0.03285509 0.00016482 0.03405535\n",
      "  0.01264636]\n",
      " [0.00051306 0.00019035 0.01327874 0.00263016 0.93465046 0.00030137\n",
      "  0.04843585]\n",
      " [0.08816658 0.0009487  0.08432651 0.32076378 0.06657111 0.00678169\n",
      "  0.43244163]\n",
      " [0.19550749 0.00000081 0.00034531 0.41773234 0.00003966 0.38631429\n",
      "  0.0000601 ]\n",
      " [0.0235096  0.00199589 0.17862117 0.03297214 0.45340604 0.27888446\n",
      "  0.03061071]\n",
      " [0.01079215 0.00059657 0.0035149  0.97762858 0.00622625 0.00014675\n",
      "  0.0010948 ]\n",
      " [0.02913471 0.00002234 0.00132035 0.00579825 0.8956488  0.00001542\n",
      "  0.06806013]\n",
      " [0.02738683 0.00001603 0.00710393 0.00003368 0.01748967 0.00446087\n",
      "  0.94350899]\n",
      " [0.02734925 0.00167498 0.06374691 0.76954716 0.00386346 0.03405417\n",
      "  0.09976406]\n",
      " [0.39112442 0.00113491 0.00159848 0.00531174 0.08063527 0.2409904\n",
      "  0.27920478]\n",
      " [0.00018039 0.00054201 0.01927865 0.03044087 0.00069247 0.94634323\n",
      "  0.00252238]\n",
      " [0.00000327 0.         0.00022839 0.00000281 0.00000153 0.9997449\n",
      "  0.0000191 ]\n",
      " [0.00003853 0.00000005 0.00000187 0.99995546 0.00000024 0.00000148\n",
      "  0.00000236]\n",
      " [0.53405234 0.00001344 0.03092339 0.28108719 0.1458355  0.0001314\n",
      "  0.00795674]\n",
      " [0.05330207 0.008384   0.04067252 0.00243178 0.3068637  0.00406517\n",
      "  0.58428077]\n",
      " [0.05760917 0.00009155 0.8988491  0.00960164 0.0090015  0.00212566\n",
      "  0.02272139]\n",
      " [0.01856172 0.0075878  0.06763032 0.0081898  0.41788807 0.30196772\n",
      "  0.17817457]\n",
      " [0.00363543 0.00010807 0.00013237 0.99042432 0.00437593 0.0001562\n",
      "  0.00116768]\n",
      " [0.35440227 0.00772768 0.05789374 0.0051898  0.0206303  0.0196011\n",
      "  0.53455511]\n",
      " [0.02608019 0.00228959 0.49770546 0.00422386 0.44279364 0.00011894\n",
      "  0.02678833]\n",
      " [0.00166125 0.99034963 0.00016933 0.00011764 0.00761962 0.00002706\n",
      "  0.00005548]\n",
      " [0.04838166 0.00456842 0.00413269 0.05847957 0.07403239 0.00281562\n",
      "  0.80758965]\n",
      " [0.39717617 0.00123501 0.00391099 0.02542972 0.09136064 0.33528142\n",
      "  0.14560604]\n",
      " [0.729455   0.00116487 0.00692323 0.19335341 0.00799742 0.00032812\n",
      "  0.06077796]\n",
      " [0.0063038  0.00021219 0.00000152 0.99299253 0.00000406 0.00043723\n",
      "  0.00004868]\n",
      " [0.65841809 0.00022342 0.22553876 0.00523432 0.06418634 0.04489479\n",
      "  0.00150427]\n",
      " [0.00005124 0.00006282 0.00000395 0.9947412  0.00071897 0.00000144\n",
      "  0.00442038]\n",
      " [0.00258397 0.00024352 0.00379998 0.00000181 0.00470852 0.01759627\n",
      "  0.97106594]\n",
      " [0.02375843 0.00000063 0.0000214  0.96072652 0.00035314 0.00001466\n",
      "  0.01512521]\n",
      " [0.01935041 0.00058138 0.00086925 0.84012143 0.13694471 0.00116541\n",
      "  0.00096742]\n",
      " [0.00010932 0.00000073 0.56779419 0.00003192 0.0001347  0.43169594\n",
      "  0.0002332 ]\n",
      " [0.00142383 0.0000819  0.01288934 0.41694652 0.40153688 0.00001687\n",
      "  0.16710466]\n",
      " [0.00056281 0.00001912 0.00030375 0.99487744 0.00191895 0.00032096\n",
      "  0.00199697]\n",
      " [0.02200227 0.0000177  0.08022362 0.64707505 0.24987449 0.00009971\n",
      "  0.00070716]\n",
      " [0.0302171  0.00000605 0.00152353 0.95863655 0.00004439 0.00140994\n",
      "  0.00816244]\n",
      " [0.14660296 0.05010413 0.13125817 0.07016241 0.4096248  0.00334519\n",
      "  0.18890235]\n",
      " [0.00048219 0.00003559 0.00001302 0.99875241 0.00000754 0.00014223\n",
      "  0.00056701]\n",
      " [0.96800948 0.00022207 0.00081501 0.00006122 0.03084317 0.\n",
      "  0.00004904]\n",
      " [0.0205235  0.00595417 0.02011442 0.85645153 0.06921241 0.00097685\n",
      "  0.02676711]\n",
      " [0.00982132 0.00081043 0.02143465 0.00010299 0.04905064 0.29256633\n",
      "  0.62621364]\n",
      " [0.05704256 0.00014249 0.00406492 0.00000024 0.12255022 0.00482222\n",
      "  0.81137737]\n",
      " [0.00001111 0.00010749 0.00758463 0.56851776 0.12841469 0.28938011\n",
      "  0.00598421]\n",
      " [0.0122499  0.00001265 0.00654821 0.0357621  0.8478208  0.00014923\n",
      "  0.09745711]\n",
      " [0.02134801 0.00022534 0.01793582 0.14723519 0.35654372 0.00006488\n",
      "  0.45664703]\n",
      " [0.25307551 0.01914427 0.01991515 0.07296028 0.44281707 0.14780436\n",
      "  0.04428336]] (83.168 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8447626829147339, step = 32500 (16.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02011\n",
      "INFO:tensorflow:loss = 0.40794336795806885, step = 32600 (16.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.99757\n",
      "INFO:tensorflow:loss = 0.4108279049396515, step = 32700 (16.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.00927\n",
      "INFO:tensorflow:loss = 0.6624292135238647, step = 32800 (16.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.00846\n",
      "INFO:tensorflow:loss = 0.5495033860206604, step = 32900 (16.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.01157\n",
      "INFO:tensorflow:probabilities = [[0.00000406 0.00000005 0.00006608 0.99992751 0.00000142 0.00000021\n",
      "  0.00000067]\n",
      " [0.01288947 0.01135876 0.59427226 0.00360828 0.18953176 0.00008759\n",
      "  0.18825188]\n",
      " [0.00460887 0.00002468 0.0582095  0.00947053 0.90474092 0.00267783\n",
      "  0.02026767]\n",
      " [0.0521377  0.01018628 0.02123982 0.0052544  0.86757089 0.000025\n",
      "  0.04358591]\n",
      " [0.13651921 0.00004088 0.01048191 0.05806785 0.46581927 0.00000848\n",
      "  0.32906242]\n",
      " [0.84685208 0.00055943 0.01427173 0.02164192 0.08952109 0.00643416\n",
      "  0.0207196 ]\n",
      " [0.63734739 0.00067579 0.03113955 0.05166485 0.24529095 0.00070329\n",
      "  0.03317819]\n",
      " [0.13034044 0.00139665 0.03003114 0.16014523 0.16898374 0.02246491\n",
      "  0.4866379 ]\n",
      " [0.65740876 0.00633029 0.15142081 0.00459874 0.00359213 0.0681191\n",
      "  0.10853018]\n",
      " [0.00557374 0.00002849 0.10821161 0.00000416 0.84476396 0.0000087\n",
      "  0.04140934]\n",
      " [0.01192241 0.00269604 0.03195034 0.93841786 0.00367912 0.00483813\n",
      "  0.0064961 ]\n",
      " [0.03124208 0.00000819 0.00000947 0.00000699 0.00004737 0.00000182\n",
      "  0.96868409]\n",
      " [0.14165619 0.00023403 0.003863   0.84718571 0.00307048 0.00191099\n",
      "  0.00207961]\n",
      " [0.00128298 0.00000138 0.10259409 0.00029634 0.00153661 0.89420369\n",
      "  0.00008492]\n",
      " [0.51014493 0.00055313 0.01095034 0.03723931 0.08155321 0.00005021\n",
      "  0.35950886]\n",
      " [0.04763631 0.00967459 0.0028627  0.00107611 0.92452968 0.00183297\n",
      "  0.01238764]\n",
      " [0.33958452 0.08252191 0.37750455 0.06212879 0.02244365 0.02747321\n",
      "  0.08834337]\n",
      " [0.0003194  0.00000215 0.02314663 0.00000001 0.01242357 0.00001453\n",
      "  0.96409371]\n",
      " [0.0024753  0.00297152 0.34566403 0.62437472 0.01597393 0.000211\n",
      "  0.00832949]\n",
      " [0.60129645 0.00333988 0.08654588 0.22159658 0.04224571 0.00279233\n",
      "  0.04218318]\n",
      " [0.00093174 0.00002616 0.00034879 0.97376713 0.00116184 0.00002637\n",
      "  0.02373798]\n",
      " [0.59542763 0.00019973 0.00317842 0.02009701 0.30685979 0.00014078\n",
      "  0.07409665]\n",
      " [0.99886132 0.00000494 0.00004964 0.00001492 0.0000505  0.00098869\n",
      "  0.00002998]\n",
      " [0.00222863 0.00000037 0.00539386 0.0000272  0.00018717 0.98506543\n",
      "  0.00709734]\n",
      " [0.01243817 0.43160309 0.15747062 0.0093459  0.38320434 0.00089168\n",
      "  0.00504619]\n",
      " [0.00297875 0.00009815 0.00351996 0.95842422 0.0058865  0.02356922\n",
      "  0.00552321]\n",
      " [0.07608984 0.02868495 0.07662523 0.26474831 0.0941699  0.12751452\n",
      "  0.33216727]\n",
      " [0.0504094  0.00001095 0.49490134 0.15493111 0.11554241 0.1082097\n",
      "  0.07599508]\n",
      " [0.0909106  0.0007111  0.01258679 0.48166997 0.01412162 0.00032807\n",
      "  0.39967186]\n",
      " [0.50256166 0.02959631 0.19200316 0.00436893 0.04335344 0.01490914\n",
      "  0.21320737]\n",
      " [0.05234397 0.0014229  0.04283513 0.0017777  0.71079663 0.00211201\n",
      "  0.18871167]\n",
      " [0.02929417 0.00020198 0.00545513 0.94519503 0.00147851 0.00008043\n",
      "  0.01829476]\n",
      " [0.03542532 0.00152    0.24873727 0.11901242 0.03572938 0.48359098\n",
      "  0.07598465]\n",
      " [0.00125175 0.0001548  0.07387725 0.01374259 0.64568359 0.03314768\n",
      "  0.23214235]\n",
      " [0.04364268 0.00090321 0.00029702 0.95160425 0.0014522  0.00179877\n",
      "  0.00030189]\n",
      " [0.70832028 0.01179247 0.09905932 0.00048129 0.06899612 0.01514082\n",
      "  0.0962097 ]\n",
      " [0.04049011 0.00474409 0.04802751 0.05990233 0.8458379  0.00049234\n",
      "  0.00050571]\n",
      " [0.04125719 0.00215718 0.04360762 0.00825171 0.083416   0.03412784\n",
      "  0.78718246]\n",
      " [0.88132046 0.06400561 0.00954218 0.00081291 0.00966773 0.00031664\n",
      "  0.03433447]\n",
      " [0.00606575 0.0004103  0.09169979 0.73436497 0.07214738 0.07850767\n",
      "  0.01680414]\n",
      " [0.03123289 0.00001315 0.9438506  0.00001039 0.02406344 0.00004641\n",
      "  0.00078313]\n",
      " [0.0006626  0.00000006 0.72781401 0.00604374 0.0147504  0.00678616\n",
      "  0.24394303]\n",
      " [0.03191134 0.00029023 0.05339817 0.86683408 0.03143754 0.00416698\n",
      "  0.01196166]\n",
      " [0.01263799 0.00070401 0.71092388 0.07362917 0.0551878  0.00232701\n",
      "  0.14459014]\n",
      " [0.0004197  0.00000013 0.00003713 0.99950203 0.00000095 0.00002878\n",
      "  0.00001129]\n",
      " [0.05761384 0.00352577 0.28136358 0.01655901 0.02383099 0.20729356\n",
      "  0.40981325]\n",
      " [0.03749842 0.00022448 0.04669199 0.01184616 0.00351265 0.89913369\n",
      "  0.00109262]\n",
      " [0.27557287 0.00001541 0.66791376 0.00001632 0.00751781 0.01843161\n",
      "  0.03053222]\n",
      " [0.01754052 0.00032618 0.81078837 0.00059167 0.01879813 0.06100918\n",
      "  0.09094594]\n",
      " [0.00015847 0.00000011 0.00001958 0.00000954 0.00000201 0.99981023\n",
      "  0.00000005]] (83.205 sec)\n",
      "INFO:tensorflow:loss = 0.6994180679321289, step = 33000 (16.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0038\n",
      "INFO:tensorflow:loss = 0.6062445044517517, step = 33100 (16.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02884\n",
      "INFO:tensorflow:loss = 0.6348243355751038, step = 33200 (16.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.9961\n",
      "INFO:tensorflow:loss = 0.7932507991790771, step = 33300 (16.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.01054\n",
      "INFO:tensorflow:loss = 0.39661791920661926, step = 33400 (16.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0301\n",
      "INFO:tensorflow:probabilities = [[0.11726657 0.00033395 0.4962735  0.00053999 0.36624122 0.00011202\n",
      "  0.01923275]\n",
      " [0.00029092 0.00024565 0.00035521 0.99603567 0.00035889 0.00051788\n",
      "  0.00219578]\n",
      " [0.02438729 0.00000155 0.00902656 0.30733976 0.46337959 0.00014973\n",
      "  0.19571551]\n",
      " [0.00124066 0.00004145 0.00004311 0.00057016 0.00013864 0.99414773\n",
      "  0.00381824]\n",
      " [0.11435421 0.02039964 0.15866722 0.00446115 0.04395186 0.02352459\n",
      "  0.63464132]\n",
      " [0.00000291 0.00000063 0.00000143 0.99998917 0.00000175 0.00000286\n",
      "  0.00000125]\n",
      " [0.01316876 0.00092254 0.01051278 0.25301065 0.05600039 0.00630994\n",
      "  0.66007495]\n",
      " [0.14378406 0.24748524 0.0980735  0.47433724 0.03044877 0.00298029\n",
      "  0.0028909 ]\n",
      " [0.0081554  0.         0.98240925 0.         0.00004029 0.00728363\n",
      "  0.00211143]\n",
      " [0.00260903 0.00000279 0.01644424 0.97860319 0.00208766 0.00001168\n",
      "  0.0002414 ]\n",
      " [0.00101932 0.00000236 0.11559758 0.88145262 0.00080335 0.0000374\n",
      "  0.00108738]\n",
      " [0.51035395 0.00408819 0.00852225 0.0646188  0.39026368 0.02152588\n",
      "  0.00062725]\n",
      " [0.00430843 0.00102735 0.07925501 0.7146407  0.14244787 0.00063314\n",
      "  0.0576875 ]\n",
      " [0.00010778 0.00004794 0.00030965 0.99937256 0.00003408 0.00001299\n",
      "  0.00011499]\n",
      " [0.04658501 0.00306105 0.00986828 0.78994849 0.01985829 0.00798044\n",
      "  0.12269844]\n",
      " [0.00083498 0.00004737 0.00146132 0.00006189 0.99716357 0.00000038\n",
      "  0.0004305 ]\n",
      " [0.00117027 0.00000028 0.00406807 0.00808737 0.98514202 0.00000339\n",
      "  0.00152859]\n",
      " [0.01059661 0.01357175 0.15069074 0.56365445 0.1433241  0.00535163\n",
      "  0.11281072]\n",
      " [0.00507204 0.00079532 0.02358652 0.05731184 0.00624581 0.00682134\n",
      "  0.90016712]\n",
      " [0.41301861 0.00332861 0.14957017 0.05061418 0.02182595 0.00839273\n",
      "  0.35324974]\n",
      " [0.05588814 0.00271576 0.60056367 0.00185337 0.1074714  0.00308715\n",
      "  0.2284205 ]\n",
      " [0.03270022 0.94746967 0.00718218 0.00081631 0.00358692 0.00001446\n",
      "  0.00823022]\n",
      " [0.12158045 0.00000176 0.00079562 0.22936124 0.63961937 0.00003057\n",
      "  0.00861098]\n",
      " [0.04160791 0.01341249 0.00983775 0.93088453 0.00282576 0.00084029\n",
      "  0.00059127]\n",
      " [0.02177075 0.00000008 0.00749885 0.76437327 0.09999874 0.00784321\n",
      "  0.09851511]\n",
      " [0.10648713 0.00438149 0.42544341 0.00033589 0.08031449 0.00126769\n",
      "  0.38176991]\n",
      " [0.00028812 0.0001988  0.00062015 0.99349754 0.00141385 0.00148326\n",
      "  0.00249829]\n",
      " [0.76959219 0.00496666 0.01783185 0.04078132 0.01586129 0.09746777\n",
      "  0.05349891]\n",
      " [0.00003491 0.00000004 0.00012075 0.0031588  0.00000016 0.99668532\n",
      "  0.00000001]\n",
      " [0.00123094 0.00026925 0.00083451 0.97884112 0.01148308 0.00004008\n",
      "  0.00730102]\n",
      " [0.17682606 0.00247695 0.02320567 0.32278302 0.16128487 0.09581125\n",
      "  0.21761217]\n",
      " [0.00358965 0.00004905 0.00441394 0.00005133 0.49965054 0.1297301\n",
      "  0.36251539]\n",
      " [0.01813763 0.0001508  0.73964364 0.00988653 0.00519423 0.00131457\n",
      "  0.22567261]\n",
      " [0.01703427 0.0011933  0.02932089 0.00163997 0.00992599 0.92241412\n",
      "  0.01847147]\n",
      " [0.88559281 0.03270801 0.00886051 0.00010568 0.0201763  0.00037051\n",
      "  0.05218618]\n",
      " [0.48108001 0.05299264 0.01174988 0.0025874  0.37058772 0.00085292\n",
      "  0.08014942]\n",
      " [0.00084677 0.00000316 0.99862338 0.00000709 0.00047405 0.00000009\n",
      "  0.00004547]\n",
      " [0.13720521 0.01243779 0.74694697 0.02360627 0.02342104 0.03442364\n",
      "  0.02195907]\n",
      " [0.00086626 0.00003535 0.00026724 0.00002302 0.00021215 0.99854638\n",
      "  0.0000496 ]\n",
      " [0.06690141 0.00004083 0.01827243 0.00879924 0.00038049 0.90557035\n",
      "  0.00003524]\n",
      " [0.90491783 0.01095965 0.00607346 0.06727057 0.00672868 0.00000014\n",
      "  0.00404967]\n",
      " [0.97739044 0.00537719 0.00604026 0.00023761 0.00555397 0.00029285\n",
      "  0.00510767]\n",
      " [0.00811268 0.0002023  0.05077368 0.06199188 0.01802187 0.00363399\n",
      "  0.85726361]\n",
      " [0.61776326 0.00000376 0.00030404 0.01427819 0.0246164  0.0008523\n",
      "  0.34218206]\n",
      " [0.00225445 0.000122   0.00530889 0.02877482 0.96177813 0.00000009\n",
      "  0.00176162]\n",
      " [0.19114811 0.00633961 0.36596931 0.19492135 0.02589702 0.2123323\n",
      "  0.0033923 ]\n",
      " [0.00029718 0.00004887 0.15163507 0.0118076  0.00000141 0.83620077\n",
      "  0.0000091 ]\n",
      " [0.0340054  0.00005017 0.0018555  0.13545209 0.00128579 0.8075443\n",
      "  0.01980675]\n",
      " [0.04826223 0.00006634 0.03443896 0.03149547 0.82475745 0.00399506\n",
      "  0.05698449]\n",
      " [0.31680166 0.02480359 0.41003652 0.00149088 0.21847571 0.00092748\n",
      "  0.02746418]] (83.140 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5045365691184998, step = 33500 (16.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04603\n",
      "INFO:tensorflow:loss = 0.7444038987159729, step = 33600 (16.535 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 33608 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 5.77529\n",
      "INFO:tensorflow:loss = 0.5232824087142944, step = 33700 (17.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04769\n",
      "INFO:tensorflow:loss = 0.4827299416065216, step = 33800 (16.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03882\n",
      "INFO:tensorflow:loss = 0.4796559810638428, step = 33900 (16.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03995\n",
      "INFO:tensorflow:probabilities = [[0.00274882 0.00210315 0.96900915 0.00009122 0.0147902  0.00873048\n",
      "  0.00252698]\n",
      " [0.10957917 0.0089112  0.12447734 0.01323688 0.59692174 0.01122851\n",
      "  0.13564517]\n",
      " [0.54119965 0.0109749  0.28911113 0.01732526 0.02715258 0.08912165\n",
      "  0.02511483]\n",
      " [0.19487478 0.00391948 0.48144652 0.00043692 0.28849596 0.01354926\n",
      "  0.01727707]\n",
      " [0.00060015 0.00004231 0.00000671 0.99870715 0.00005709 0.00000989\n",
      "  0.0005767 ]\n",
      " [0.00003949 0.00000267 0.00021467 0.99964915 0.00004148 0.00000093\n",
      "  0.00005161]\n",
      " [0.31427276 0.00000052 0.00013056 0.00810256 0.00090401 0.0000117\n",
      "  0.67657789]\n",
      " [0.00006133 0.00000407 0.00002873 0.99976965 0.00001919 0.00002942\n",
      "  0.0000876 ]\n",
      " [0.11626555 0.00001661 0.00003386 0.87368606 0.00133963 0.0001385\n",
      "  0.00851979]\n",
      " [0.54337203 0.00001395 0.03263547 0.36951004 0.05223579 0.00006093\n",
      "  0.00217179]\n",
      " [0.00000003 0.00000536 0.00000001 0.99991829 0.00000019 0.00000098\n",
      "  0.00007515]\n",
      " [0.00484062 0.00005658 0.00803491 0.15491986 0.14046485 0.00562996\n",
      "  0.68605321]\n",
      " [0.99931888 0.00000025 0.00050763 0.00015899 0.00000595 0.00000802\n",
      "  0.00000028]\n",
      " [0.00508753 0.0000002  0.95927871 0.00000366 0.00006715 0.03538043\n",
      "  0.00018232]\n",
      " [0.00158667 0.00000019 0.00003363 0.99410112 0.00000616 0.00023325\n",
      "  0.00403899]\n",
      " [0.00000603 0.00000134 0.00066165 0.99210395 0.00019966 0.00036849\n",
      "  0.00665889]\n",
      " [0.00199717 0.00029144 0.22184681 0.00001425 0.00308516 0.76350211\n",
      "  0.00926307]\n",
      " [0.92600514 0.00212769 0.06492005 0.00019323 0.00473331 0.00072585\n",
      "  0.00129474]\n",
      " [0.81770358 0.00001011 0.00362207 0.00012636 0.1226971  0.04288713\n",
      "  0.01295365]\n",
      " [0.94592315 0.00021864 0.00326353 0.0152191  0.00537167 0.02361575\n",
      "  0.00638815]\n",
      " [0.02797201 0.00000071 0.93901    0.00000276 0.02826993 0.00000996\n",
      "  0.00473462]\n",
      " [0.97613817 0.00020902 0.00794111 0.00000322 0.01211494 0.00012663\n",
      "  0.00346691]\n",
      " [0.02028631 0.00071893 0.01289612 0.00370086 0.09493426 0.0010453\n",
      "  0.86641822]\n",
      " [0.01538399 0.00000219 0.8147367  0.01635015 0.1449563  0.00813759\n",
      "  0.00043307]\n",
      " [0.02777619 0.00050133 0.00768794 0.73680466 0.02139689 0.00009853\n",
      "  0.20573445]\n",
      " [0.00770614 0.00000044 0.0026012  0.00078311 0.01463102 0.01945526\n",
      "  0.95482282]\n",
      " [0.04716093 0.02039685 0.09116728 0.01936526 0.81416478 0.00771266\n",
      "  0.00003224]\n",
      " [0.11442678 0.00016068 0.03400654 0.00770169 0.66495467 0.02960717\n",
      "  0.14914247]\n",
      " [0.09021023 0.02733075 0.1519151  0.5284929  0.15832646 0.0010573\n",
      "  0.04266726]\n",
      " [0.18319984 0.0035121  0.0127686  0.00982279 0.73008367 0.0043751\n",
      "  0.05623789]\n",
      " [0.04927597 0.0014724  0.04094684 0.00037618 0.035284   0.00107457\n",
      "  0.87157004]\n",
      " [0.00348433 0.00206364 0.46180453 0.00243786 0.51637389 0.00042356\n",
      "  0.01341219]\n",
      " [0.00494043 0.00001561 0.02363433 0.00009234 0.0017047  0.96281667\n",
      "  0.00679592]\n",
      " [0.12994175 0.00395144 0.04353285 0.01454729 0.15063293 0.00099708\n",
      "  0.65639667]\n",
      " [0.66376643 0.0000621  0.00085022 0.04931672 0.0685136  0.00001035\n",
      "  0.21748059]\n",
      " [0.15856027 0.01199497 0.30567287 0.19356183 0.06936941 0.24948762\n",
      "  0.01135304]\n",
      " [0.98591009 0.00086584 0.01202593 0.00001094 0.00072706 0.00025837\n",
      "  0.00020178]\n",
      " [0.00001495 0.00000002 0.0051175  0.32929842 0.00000974 0.66435217\n",
      "  0.0012072 ]\n",
      " [0.0029577  0.00003504 0.04359033 0.00076137 0.94860685 0.00394988\n",
      "  0.00009883]\n",
      " [0.05553918 0.00511988 0.00013164 0.89927105 0.02917637 0.00006021\n",
      "  0.01070167]\n",
      " [0.65345082 0.00004784 0.03067016 0.00037911 0.00816796 0.00005064\n",
      "  0.30723347]\n",
      " [0.10985041 0.00051183 0.01499199 0.84722228 0.00862566 0.00082204\n",
      "  0.01797579]\n",
      " [0.00430757 0.00000222 0.91963428 0.05022883 0.02200286 0.00212914\n",
      "  0.0016951 ]\n",
      " [0.05586142 0.00002714 0.69453199 0.00158518 0.17985768 0.01022205\n",
      "  0.05791454]\n",
      " [0.00165175 0.00001053 0.64349408 0.00036407 0.33912572 0.00235424\n",
      "  0.01299961]\n",
      " [0.04993227 0.00548841 0.00063098 0.90871452 0.00004822 0.03206778\n",
      "  0.00311783]\n",
      " [0.01421548 0.00035297 0.2297931  0.65486158 0.03015466 0.06515823\n",
      "  0.00546398]\n",
      " [0.00030143 0.0002892  0.00020407 0.00139329 0.00121354 0.99653477\n",
      "  0.0000637 ]\n",
      " [0.20563599 0.00395969 0.10772357 0.0059474  0.62798208 0.00027817\n",
      "  0.04847309]\n",
      " [0.66489178 0.00016717 0.20191202 0.03638935 0.01437922 0.03315832\n",
      "  0.04910214]] (83.522 sec)\n",
      "INFO:tensorflow:loss = 0.7999477386474609, step = 34000 (16.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.01868\n",
      "INFO:tensorflow:loss = 0.4337007701396942, step = 34100 (16.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05168\n",
      "INFO:tensorflow:loss = 0.6364265084266663, step = 34200 (16.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.00537\n",
      "INFO:tensorflow:loss = 0.4187474846839905, step = 34300 (16.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0178\n",
      "INFO:tensorflow:loss = 0.8696437478065491, step = 34400 (16.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0456\n",
      "INFO:tensorflow:probabilities = [[0.43937175 0.00116341 0.01196427 0.016669   0.02349297 0.00000704\n",
      "  0.50733156]\n",
      " [0.00578745 0.09754427 0.68265555 0.00733054 0.19361161 0.00034284\n",
      "  0.01272773]\n",
      " [0.05162595 0.00007543 0.01543009 0.00001647 0.77947325 0.00063415\n",
      "  0.15274466]\n",
      " [0.01807935 0.02656765 0.88901947 0.05696994 0.0074128  0.00123009\n",
      "  0.0007207 ]\n",
      " [0.00580428 0.00616035 0.15793873 0.00093556 0.59600554 0.05249873\n",
      "  0.18065681]\n",
      " [0.00229584 0.00025107 0.00021231 0.99488194 0.00221994 0.00012413\n",
      "  0.00001477]\n",
      " [0.01972779 0.00107249 0.05186892 0.00012923 0.41590182 0.46682287\n",
      "  0.04447688]\n",
      " [0.00193543 0.21396533 0.55529512 0.00486691 0.12761483 0.09049921\n",
      "  0.00582315]\n",
      " [0.04619572 0.00101951 0.00286272 0.01343905 0.02252042 0.05121089\n",
      "  0.8627517 ]\n",
      " [0.95164572 0.00001069 0.0010979  0.00067741 0.04427915 0.00000093\n",
      "  0.00228819]\n",
      " [0.00008142 0.0001378  0.00004418 0.99954938 0.00006792 0.0000215\n",
      "  0.00009779]\n",
      " [0.00009303 0.00037108 0.93790503 0.00003101 0.01597846 0.00000068\n",
      "  0.0456207 ]\n",
      " [0.04374536 0.00028598 0.68122246 0.00142623 0.07850307 0.00188171\n",
      "  0.19293519]\n",
      " [0.04197496 0.01953125 0.32776717 0.01360155 0.13142265 0.01109582\n",
      "  0.45460661]\n",
      " [0.05150664 0.00120726 0.28194486 0.01911544 0.59285723 0.00000993\n",
      "  0.05335863]\n",
      " [0.00001051 0.         0.00000019 0.00006425 0.00056859 0.42191886\n",
      "  0.5774376 ]\n",
      " [0.00205593 0.00000866 0.0016926  0.98115611 0.00006287 0.00000622\n",
      "  0.01501761]\n",
      " [0.48612386 0.00030499 0.49277788 0.01192045 0.00158209 0.005573\n",
      "  0.00171773]\n",
      " [0.0009404  0.00007845 0.00046983 0.01111188 0.00255034 0.00039031\n",
      "  0.9844588 ]\n",
      " [0.0004183  0.0000017  0.0007283  0.62121261 0.00078459 0.00000158\n",
      "  0.37685292]\n",
      " [0.00000392 0.00000304 0.00000208 0.99949162 0.00002525 0.00000392\n",
      "  0.00047017]\n",
      " [0.00918369 0.00000347 0.13571464 0.07498964 0.08021079 0.69975938\n",
      "  0.00013839]\n",
      " [0.94404729 0.00109157 0.00681153 0.00152878 0.04306683 0.00217844\n",
      "  0.00127556]\n",
      " [0.00330938 0.00001138 0.62916829 0.00001112 0.08250204 0.00007636\n",
      "  0.28492143]\n",
      " [0.44569993 0.00488476 0.03991958 0.22692475 0.03743222 0.00620641\n",
      "  0.23893234]\n",
      " [0.22724076 0.00051483 0.10200918 0.15837687 0.36815701 0.0041298\n",
      "  0.13957155]\n",
      " [0.00000351 0.00000038 0.00000014 0.99999372 0.00000012 0.00000048\n",
      "  0.00000166]\n",
      " [0.00001198 0.00000736 0.00000786 0.99995935 0.00000455 0.00000367\n",
      "  0.00000522]\n",
      " [0.7707933  0.00073744 0.00369334 0.00006822 0.151709   0.00000002\n",
      "  0.07299869]\n",
      " [0.00014417 0.00005761 0.00005487 0.99913403 0.00038559 0.00001333\n",
      "  0.00021041]\n",
      " [0.00088682 0.00004676 0.00033014 0.68160746 0.24728819 0.02674813\n",
      "  0.04309251]\n",
      " [0.1091528  0.00092321 0.67916945 0.01846414 0.15300491 0.00729944\n",
      "  0.03198605]\n",
      " [0.02303743 0.00983522 0.02641797 0.90274089 0.02162304 0.01066163\n",
      "  0.00568381]\n",
      " [0.0501473  0.00000097 0.94171251 0.000007   0.00493375 0.00312088\n",
      "  0.0000776 ]\n",
      " [0.00036403 0.00005255 0.00345783 0.0005205  0.35953115 0.00906417\n",
      "  0.62700977]\n",
      " [0.00738635 0.0007315  0.0205806  0.92512147 0.01698785 0.01946781\n",
      "  0.00972442]\n",
      " [0.00822048 0.00195441 0.02391225 0.00003851 0.61065773 0.00017047\n",
      "  0.35504614]\n",
      " [0.12705465 0.00025564 0.053899   0.00399129 0.29144507 0.01690806\n",
      "  0.50644629]\n",
      " [0.02250836 0.00035223 0.01249822 0.91551028 0.04544174 0.00067268\n",
      "  0.00301648]\n",
      " [0.00464278 0.00097049 0.16752704 0.00395826 0.38194843 0.03751313\n",
      "  0.40343987]\n",
      " [0.05107722 0.00047098 0.03005351 0.01263385 0.23628226 0.5308348\n",
      "  0.1386474 ]\n",
      " [0.01598695 0.02435829 0.48324445 0.00340534 0.34096999 0.11168795\n",
      "  0.02034704]\n",
      " [0.01360715 0.00005361 0.02537425 0.00769196 0.01772237 0.03941069\n",
      "  0.89613996]\n",
      " [0.58934989 0.003614   0.00386864 0.11933488 0.16946847 0.00002017\n",
      "  0.11434396]\n",
      " [0.0054853  0.00015    0.01129955 0.00019834 0.17471957 0.00016931\n",
      "  0.80797793]\n",
      " [0.01107293 0.00008401 0.00339497 0.00003687 0.00532342 0.00055146\n",
      "  0.97953635]\n",
      " [0.01169224 0.00017768 0.01310756 0.00162893 0.93480748 0.00186104\n",
      "  0.03672507]\n",
      " [0.03778147 0.01418922 0.55743661 0.00371546 0.2677951  0.00309478\n",
      "  0.11598737]\n",
      " [0.00000038 0.00000002 0.0000006  0.99999156 0.00000033 0.00000187\n",
      "  0.00000524]\n",
      " [0.01028154 0.00045128 0.00391593 0.00065743 0.24919619 0.73498203\n",
      "  0.0005156 ]] (82.934 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7223781943321228, step = 34500 (16.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04294\n",
      "INFO:tensorflow:loss = 0.5521799921989441, step = 34600 (16.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03821\n",
      "INFO:tensorflow:loss = 0.7128893136978149, step = 34700 (16.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04895\n",
      "INFO:tensorflow:loss = 0.5711194276809692, step = 34800 (16.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04887\n",
      "INFO:tensorflow:loss = 0.5288806557655334, step = 34900 (16.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05049\n",
      "INFO:tensorflow:probabilities = [[0.05600315 0.05993791 0.09957433 0.00028555 0.29108886 0.00225272\n",
      "  0.49085749]\n",
      " [0.14661289 0.06458412 0.43020472 0.00081755 0.20782829 0.00443467\n",
      "  0.14551775]\n",
      " [0.00000533 0.         0.00000018 0.99998211 0.         0.00000002\n",
      "  0.00001236]\n",
      " [0.011708   0.00002019 0.02787449 0.16997084 0.76496682 0.00060942\n",
      "  0.02485025]\n",
      " [0.02019619 0.00039483 0.47137994 0.3622085  0.07825658 0.00092935\n",
      "  0.06663461]\n",
      " [0.00991451 0.00097198 0.00481905 0.91458769 0.03735845 0.00053984\n",
      "  0.03180848]\n",
      " [0.00104427 0.0002389  0.00209396 0.95211881 0.0013729  0.00026972\n",
      "  0.04286144]\n",
      " [0.00475486 0.00005577 0.0152465  0.89157519 0.08749874 0.00059561\n",
      "  0.00027333]\n",
      " [0.03383961 0.00000039 0.02710778 0.06528397 0.30585883 0.28285419\n",
      "  0.28505523]\n",
      " [0.19395795 0.00064772 0.00730716 0.00405951 0.0441837  0.0007578\n",
      "  0.74908616]\n",
      " [0.0036221  0.00024685 0.00130463 0.02363123 0.93358451 0.03752178\n",
      "  0.0000889 ]\n",
      " [0.04712492 0.00656645 0.43116634 0.00889499 0.39825039 0.06077327\n",
      "  0.04722364]\n",
      " [0.00139193 0.00000008 0.99497939 0.00002906 0.00001701 0.00357916\n",
      "  0.00000337]\n",
      " [0.58071795 0.00389532 0.00727736 0.30732449 0.03943822 0.00354805\n",
      "  0.05779861]\n",
      " [0.00000639 0.00000001 0.00001256 0.00000343 0.00000855 0.00000866\n",
      "  0.99996039]\n",
      " [0.00008529 0.00001878 0.9615797  0.00094154 0.00671846 0.02554771\n",
      "  0.00510852]\n",
      " [0.00118688 0.00026613 0.00612923 0.0017201  0.26006122 0.00064758\n",
      "  0.72998886]\n",
      " [0.08932986 0.00654811 0.01246781 0.00063694 0.75375744 0.00341419\n",
      "  0.13384564]\n",
      " [0.00330963 0.00238894 0.03875304 0.00727297 0.73870373 0.01340186\n",
      "  0.19616981]\n",
      " [0.00134806 0.00067772 0.03561332 0.92985436 0.02935035 0.00028098\n",
      "  0.00287521]\n",
      " [0.20602899 0.00164186 0.06198155 0.44084685 0.15173614 0.01417818\n",
      "  0.12358644]\n",
      " [0.01301429 0.00007238 0.00945443 0.00061066 0.00376768 0.96813323\n",
      "  0.00494734]\n",
      " [0.0530647  0.00057132 0.44368047 0.10844888 0.015737   0.33094384\n",
      "  0.04755379]\n",
      " [0.86373576 0.00000091 0.08614279 0.00005945 0.0050023  0.0001772\n",
      "  0.04488159]\n",
      " [0.01030741 0.00000256 0.00014241 0.97938743 0.00695002 0.00003279\n",
      "  0.00317738]\n",
      " [0.02955834 0.00449523 0.03610861 0.00524733 0.162659   0.00867259\n",
      "  0.7532589 ]\n",
      " [0.22855367 0.00016945 0.23268993 0.248029   0.18693672 0.00520507\n",
      "  0.09841615]\n",
      " [0.00018257 0.00000825 0.00139842 0.00027888 0.00035725 0.99754715\n",
      "  0.00022748]\n",
      " [0.00478322 0.0103921  0.00396437 0.01722908 0.96272123 0.00008445\n",
      "  0.00082554]\n",
      " [0.00008032 0.00000141 0.00004185 0.99950873 0.0001711  0.00005865\n",
      "  0.00013795]\n",
      " [0.56734653 0.00437081 0.02523417 0.0000301  0.08014553 0.00706468\n",
      "  0.31580817]\n",
      " [0.01322003 0.00016234 0.0705797  0.00002114 0.70190818 0.00527199\n",
      "  0.20883663]\n",
      " [0.33301928 0.00357242 0.01507913 0.05949994 0.08784583 0.00022003\n",
      "  0.50076336]\n",
      " [0.42892725 0.00003501 0.06712325 0.00029223 0.02760003 0.00382017\n",
      "  0.47220206]\n",
      " [0.00035511 0.00000086 0.35678402 0.00072736 0.0152328  0.00846682\n",
      "  0.61843304]\n",
      " [0.00266212 0.00001912 0.0009797  0.98958087 0.00260164 0.00340833\n",
      "  0.00074822]\n",
      " [0.0060613  0.05303758 0.90781123 0.01828534 0.00674129 0.00328489\n",
      "  0.00477839]\n",
      " [0.10841657 0.00100326 0.44632103 0.00768082 0.24764411 0.00130334\n",
      "  0.18763088]\n",
      " [0.02011572 0.9215076  0.04243158 0.00450964 0.00655237 0.00411603\n",
      "  0.00076706]\n",
      " [0.01494781 0.00225479 0.02480447 0.86080894 0.0160483  0.0804115\n",
      "  0.00072419]\n",
      " [0.02880224 0.00010136 0.00084398 0.00444274 0.00672351 0.00001208\n",
      "  0.95907409]\n",
      " [0.03302263 0.00001542 0.00418939 0.9034539  0.00167887 0.00000156\n",
      "  0.05763824]\n",
      " [0.00012872 0.00000001 0.74266414 0.0203218  0.22753263 0.00184569\n",
      "  0.00750701]\n",
      " [0.05283424 0.0086117  0.37155443 0.06484179 0.18699352 0.00706047\n",
      "  0.30810385]\n",
      " [0.01955752 0.00016057 0.00826884 0.01575977 0.20182976 0.00063094\n",
      "  0.75379259]\n",
      " [0.00019403 0.00000107 0.0010922  0.00003467 0.00005021 0.99722661\n",
      "  0.00140121]\n",
      " [0.39029988 0.00003946 0.01851231 0.00001189 0.07174785 0.00066042\n",
      "  0.51872818]\n",
      " [0.01950972 0.00076497 0.02882361 0.01993828 0.00070653 0.82171354\n",
      "  0.10854336]\n",
      " [0.00239229 0.0010647  0.00006579 0.00164459 0.97621923 0.0000234\n",
      "  0.01859   ]\n",
      " [0.06183069 0.0006985  0.00415669 0.00006248 0.00378795 0.25730002\n",
      "  0.67216367]] (82.700 sec)\n",
      "INFO:tensorflow:loss = 0.42858490347862244, step = 35000 (16.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04003\n",
      "INFO:tensorflow:loss = 0.36714255809783936, step = 35100 (16.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04828\n",
      "INFO:tensorflow:loss = 0.5378751158714294, step = 35200 (16.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04801\n",
      "INFO:tensorflow:loss = 0.6732666492462158, step = 35300 (16.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05267\n",
      "INFO:tensorflow:loss = 0.5462287068367004, step = 35400 (16.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04936\n",
      "INFO:tensorflow:probabilities = [[0.00112443 0.00001259 0.0003997  0.99257982 0.0009405  0.00003163\n",
      "  0.00491132]\n",
      " [0.00023977 0.00028396 0.00195262 0.00000385 0.04961426 0.00056759\n",
      "  0.94733794]\n",
      " [0.08886645 0.06795772 0.056585   0.00728353 0.77877216 0.00013353\n",
      "  0.00040161]\n",
      " [0.00020221 0.00004187 0.00058853 0.10880087 0.01549692 0.46050306\n",
      "  0.41436654]\n",
      " [0.61159485 0.09441878 0.09632839 0.11742619 0.07509748 0.0031955\n",
      "  0.0019388 ]\n",
      " [0.0000862  0.00007497 0.0000666  0.99942012 0.00009475 0.00000792\n",
      "  0.00024944]\n",
      " [0.00000199 0.00000001 0.00010167 0.00027033 0.00076317 0.\n",
      "  0.99886284]\n",
      " [0.24091818 0.00060154 0.13105653 0.00545967 0.51802951 0.00068317\n",
      "  0.1032514 ]\n",
      " [0.34894013 0.00090833 0.08005184 0.34480107 0.08320285 0.00647314\n",
      "  0.13562264]\n",
      " [0.00022192 0.00032395 0.02810764 0.65827724 0.00127526 0.31077078\n",
      "  0.00102321]\n",
      " [0.20401815 0.00013539 0.0029595  0.00160494 0.04170435 0.00058496\n",
      "  0.7489927 ]\n",
      " [0.12000835 0.02026674 0.06861169 0.21722464 0.48522846 0.0222868\n",
      "  0.06637331]\n",
      " [0.07020191 0.00000243 0.00767162 0.90491225 0.00167281 0.00027903\n",
      "  0.01525994]\n",
      " [0.00211948 0.00032378 0.00249566 0.97651536 0.00652265 0.00000199\n",
      "  0.01202106]\n",
      " [0.02620282 0.00020835 0.00371445 0.00056301 0.92749022 0.00000013\n",
      "  0.04182103]\n",
      " [0.08528855 0.00039697 0.00169082 0.13616434 0.04906937 0.00221138\n",
      "  0.72517856]\n",
      " [0.04151097 0.00007326 0.00771849 0.00033203 0.93944947 0.00000244\n",
      "  0.01091332]\n",
      " [0.10371807 0.00000005 0.00000722 0.         0.47670849 0.\n",
      "  0.41956617]\n",
      " [0.03553654 0.00005035 0.06844732 0.79202851 0.04287776 0.00566869\n",
      "  0.05539083]\n",
      " [0.00584671 0.11616505 0.03538586 0.00130123 0.72838823 0.00010915\n",
      "  0.11280377]\n",
      " [0.00145008 0.00000031 0.00053242 0.00000053 0.00349862 0.00000248\n",
      "  0.99451556]\n",
      " [0.11410876 0.00041606 0.07508846 0.72338408 0.02232285 0.00964547\n",
      "  0.05503431]\n",
      " [0.83097232 0.00145355 0.15690092 0.00868694 0.00003485 0.00192763\n",
      "  0.00002379]\n",
      " [0.19058887 0.0040527  0.06253682 0.02929502 0.02136271 0.00019748\n",
      "  0.6919664 ]\n",
      " [0.00000563 0.00000001 0.00607759 0.0017557  0.99203193 0.00000001\n",
      "  0.00012913]\n",
      " [0.04350852 0.00041304 0.00364029 0.83705524 0.07217607 0.02594462\n",
      "  0.01726223]\n",
      " [0.00309076 0.00000228 0.00029403 0.98661727 0.00976812 0.0000342\n",
      "  0.00019335]\n",
      " [0.00092637 0.00024334 0.00034085 0.99748548 0.0000802  0.0001064\n",
      "  0.00081735]\n",
      " [0.31614636 0.00052868 0.01296978 0.49786348 0.15635478 0.00198772\n",
      "  0.01414919]\n",
      " [0.10627785 0.00189157 0.05262834 0.05287719 0.08350502 0.4563807\n",
      "  0.24643935]\n",
      " [0.00056826 0.00002301 0.0005247  0.00006324 0.01598514 0.00002092\n",
      "  0.98281473]\n",
      " [0.00022678 0.00001654 0.11035803 0.05332475 0.01494937 0.79255935\n",
      "  0.02856518]\n",
      " [0.66743155 0.0144766  0.03187744 0.26037569 0.01913977 0.00021579\n",
      "  0.00648315]\n",
      " [0.16942084 0.00045834 0.02095071 0.00440261 0.09823003 0.00202201\n",
      "  0.70451546]\n",
      " [0.01462983 0.00000005 0.00035228 0.00009847 0.00000667 0.98491263\n",
      "  0.00000007]\n",
      " [0.02435485 0.00090164 0.84322086 0.00283906 0.12660984 0.00006163\n",
      "  0.00201213]\n",
      " [0.07179402 0.00684726 0.00784553 0.00860995 0.05062168 0.00004548\n",
      "  0.85423608]\n",
      " [0.17375402 0.00022317 0.46442967 0.05580227 0.27905381 0.01143721\n",
      "  0.01529985]\n",
      " [0.00000088 0.00004141 0.00021954 0.99009753 0.00916271 0.00000978\n",
      "  0.00046816]\n",
      " [0.00048939 0.00033925 0.0000118  0.99507425 0.00402501 0.00005254\n",
      "  0.00000777]\n",
      " [0.00657677 0.00009087 0.0002477  0.98680336 0.00011633 0.0000147\n",
      "  0.00615028]\n",
      " [0.00727076 0.00011003 0.01607173 0.92813141 0.02486611 0.01055122\n",
      "  0.01299874]\n",
      " [0.00111355 0.00000071 0.88199712 0.00000095 0.01182126 0.10492918\n",
      "  0.00013723]\n",
      " [0.05283322 0.00000678 0.24729729 0.00003175 0.26774644 0.00015109\n",
      "  0.43193343]\n",
      " [0.0010516  0.0000316  0.00033727 0.99807174 0.00036855 0.0001129\n",
      "  0.00002634]\n",
      " [0.00053665 0.00002941 0.00021349 0.99496197 0.00018157 0.0000072\n",
      "  0.00406971]\n",
      " [0.00893576 0.00013262 0.00090927 0.97475665 0.00078194 0.00019515\n",
      "  0.0142886 ]\n",
      " [0.10532092 0.00001067 0.02271895 0.86684829 0.00153735 0.00352079\n",
      "  0.00004304]\n",
      " [0.013539   0.0024745  0.07251647 0.31012154 0.07945644 0.20230697\n",
      "  0.31958508]\n",
      " [0.21153509 0.00013776 0.03184405 0.26187418 0.32240158 0.1290549\n",
      "  0.04315244]] (82.676 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6129801273345947, step = 35500 (16.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0477\n",
      "INFO:tensorflow:loss = 0.6720611453056335, step = 35600 (16.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.046\n",
      "INFO:tensorflow:loss = 0.5993038415908813, step = 35700 (16.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04946\n",
      "INFO:tensorflow:loss = 0.6558942794799805, step = 35800 (16.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04929\n",
      "INFO:tensorflow:loss = 0.3045785129070282, step = 35900 (16.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04831\n",
      "INFO:tensorflow:probabilities = [[0.00285715 0.00015848 0.89495815 0.00177987 0.02586076 0.07396715\n",
      "  0.00041845]\n",
      " [0.10159794 0.24047889 0.09442157 0.00471736 0.48643848 0.00358467\n",
      "  0.06876109]\n",
      " [0.00000027 0.00000052 0.00000158 0.99912393 0.00000008 0.00085419\n",
      "  0.00001943]\n",
      " [0.00430653 0.0002084  0.13695822 0.07815206 0.73405271 0.00750458\n",
      "  0.0388175 ]\n",
      " [0.00125745 0.00000012 0.17695102 0.0000241  0.00002258 0.00001363\n",
      "  0.82173109]\n",
      " [0.05115494 0.00005801 0.2009806  0.04197142 0.68490642 0.00503664\n",
      "  0.01589197]\n",
      " [0.00019143 0.00001013 0.00000402 0.99917178 0.00003279 0.00002131\n",
      "  0.00056854]\n",
      " [0.00301195 0.00000288 0.0000113  0.00181691 0.995125   0.00000009\n",
      "  0.00003187]\n",
      " [0.03594916 0.02679925 0.00954146 0.00000131 0.92267459 0.00000893\n",
      "  0.00502529]\n",
      " [0.09870467 0.00320195 0.56953595 0.01436342 0.25849038 0.01147386\n",
      "  0.04422978]\n",
      " [0.10434102 0.00048131 0.04258813 0.00042194 0.25506947 0.36501497\n",
      "  0.23208317]\n",
      " [0.00000291 0.00000712 0.00080828 0.08237889 0.00032667 0.91644407\n",
      "  0.00003208]\n",
      " [0.016117   0.0092714  0.4458709  0.29129367 0.15741711 0.07953053\n",
      "  0.0004994 ]\n",
      " [0.86384972 0.00001543 0.00356524 0.0001629  0.05413949 0.04106767\n",
      "  0.03719955]\n",
      " [0.07813064 0.00102843 0.01227895 0.0018698  0.87359266 0.0013599\n",
      "  0.03173962]\n",
      " [0.01095139 0.00041007 0.00091402 0.8536651  0.00057969 0.00252728\n",
      "  0.13095244]\n",
      " [0.00235763 0.00002997 0.17389213 0.05011367 0.2929894  0.00004623\n",
      "  0.48057096]\n",
      " [0.01036993 0.00655772 0.0110911  0.00108763 0.01449921 0.95282224\n",
      "  0.00357217]\n",
      " [0.04982932 0.00005058 0.236562   0.0078431  0.67971543 0.00001671\n",
      "  0.02598286]\n",
      " [0.01342078 0.00000247 0.0069335  0.00014879 0.00100061 0.01612139\n",
      "  0.96237247]\n",
      " [0.00242207 0.00340228 0.000792   0.00089886 0.06083655 0.00041966\n",
      "  0.93122858]\n",
      " [0.00106965 0.00002073 0.00262575 0.00020103 0.00468157 0.0000487\n",
      "  0.99135257]\n",
      " [0.76870524 0.00053114 0.02691196 0.19468834 0.00597161 0.00194849\n",
      "  0.00124322]\n",
      " [0.00360079 0.00006344 0.98078079 0.00331704 0.00687134 0.00513801\n",
      "  0.0002286 ]\n",
      " [0.02059444 0.20797123 0.02474226 0.00154948 0.26935641 0.00009592\n",
      "  0.47569026]\n",
      " [0.05201305 0.00010023 0.08594525 0.00267246 0.00043169 0.00897753\n",
      "  0.84985979]\n",
      " [0.04662412 0.00022258 0.01767313 0.05960665 0.18124035 0.20936643\n",
      "  0.48526675]\n",
      " [0.00005658 0.00000064 0.0006155  0.00000019 0.99932583 0.00000015\n",
      "  0.00000112]\n",
      " [0.0000588  0.00003546 0.00005844 0.99815355 0.0014589  0.00000006\n",
      "  0.00023477]\n",
      " [0.0000317  0.00000698 0.00591853 0.00006969 0.00008271 0.99317324\n",
      "  0.00071716]\n",
      " [0.03500957 0.00125602 0.00273225 0.94582114 0.00948854 0.00362696\n",
      "  0.00206551]\n",
      " [0.02454224 0.00152133 0.84107998 0.00461945 0.01440336 0.00700299\n",
      "  0.10683065]\n",
      " [0.98559842 0.00001589 0.01373748 0.00000042 0.00001961 0.00056445\n",
      "  0.00006372]\n",
      " [0.01855598 0.18288152 0.42212006 0.22149034 0.00193476 0.01400491\n",
      "  0.13901242]\n",
      " [0.0270361  0.00000486 0.00763686 0.94595014 0.01889607 0.00001856\n",
      "  0.00045742]\n",
      " [0.00002911 0.00005117 0.00026487 0.99880717 0.0000151  0.0000001\n",
      "  0.00083248]\n",
      " [0.00023186 0.00004804 0.00477966 0.00000516 0.00004475 0.99487927\n",
      "  0.00001124]\n",
      " [0.00003161 0.00081831 0.02033561 0.89305656 0.07537973 0.00000452\n",
      "  0.01037365]\n",
      " [0.00028345 0.00002463 0.00030865 0.99912329 0.00002615 0.00010174\n",
      "  0.00013208]\n",
      " [0.00000058 0.00011428 0.00003059 0.99979646 0.00004097 0.00000007\n",
      "  0.00001705]\n",
      " [0.01279562 0.01911852 0.00148876 0.6728734  0.00264325 0.00018199\n",
      "  0.29089847]\n",
      " [0.00000756 0.         0.00001056 0.99990496 0.00007262 0.\n",
      "  0.0000043 ]\n",
      " [0.00369318 0.00000927 0.01703563 0.14947087 0.00000439 0.8282134\n",
      "  0.00157327]\n",
      " [0.00201267 0.00001415 0.13066314 0.00000017 0.00020904 0.86700228\n",
      "  0.00009855]\n",
      " [0.00378275 0.0007113  0.00397386 0.98112159 0.00342261 0.00023934\n",
      "  0.00674855]\n",
      " [0.03775162 0.00002516 0.00032457 0.00001777 0.89331688 0.00002925\n",
      "  0.06853475]\n",
      " [0.00082545 0.00115002 0.00910114 0.98557049 0.00117861 0.00031273\n",
      "  0.00186156]\n",
      " [0.05136388 0.00001177 0.67557954 0.00048589 0.13347362 0.02641158\n",
      "  0.1126737 ]\n",
      " [0.00051315 0.00000152 0.00689999 0.02025232 0.00094099 0.97113484\n",
      "  0.00025719]\n",
      " [0.00476397 0.00000178 0.00000296 0.99398604 0.00001907 0.00000143\n",
      "  0.00122475]] (82.671 sec)\n",
      "INFO:tensorflow:loss = 0.43151113390922546, step = 36000 (16.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0462\n",
      "INFO:tensorflow:loss = 0.4863949120044708, step = 36100 (16.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05016\n",
      "INFO:tensorflow:loss = 0.30570846796035767, step = 36200 (16.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05084\n",
      "INFO:tensorflow:loss = 0.7391775250434875, step = 36300 (16.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04508\n",
      "INFO:tensorflow:loss = 0.41675445437431335, step = 36400 (16.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04369\n",
      "INFO:tensorflow:probabilities = [[0.00077827 0.00003628 0.1853986  0.01351925 0.31559586 0.0125156\n",
      "  0.47215614]\n",
      " [0.00000004 0.00000003 0.00000323 0.99999295 0.00000005 0.00000099\n",
      "  0.00000271]\n",
      " [0.00192473 0.01683748 0.86350512 0.00435226 0.0388606  0.06175577\n",
      "  0.01276404]\n",
      " [0.00039729 0.00144851 0.25808528 0.00014931 0.08809009 0.04086493\n",
      "  0.6109646 ]\n",
      " [0.02657522 0.00264984 0.09348632 0.01221792 0.51372635 0.06896933\n",
      "  0.28237502]\n",
      " [0.00797101 0.00019918 0.94153236 0.00305245 0.00048219 0.04577497\n",
      "  0.00098784]\n",
      " [0.00178696 0.00076019 0.0006289  0.07808776 0.00091904 0.37665745\n",
      "  0.5411597 ]\n",
      " [0.99907118 0.00014993 0.00023514 0.00004404 0.00003191 0.00014794\n",
      "  0.00031986]\n",
      " [0.01207329 0.00663684 0.01476638 0.00136461 0.02058934 0.00006731\n",
      "  0.94450224]\n",
      " [0.03183979 0.0020387  0.34352919 0.05866794 0.3938551  0.00800613\n",
      "  0.16206315]\n",
      " [0.04313566 0.00189576 0.21379418 0.00042138 0.13858157 0.01384224\n",
      "  0.58832921]\n",
      " [0.01727308 0.02014316 0.82350181 0.0004769  0.12540513 0.00486928\n",
      "  0.00833064]\n",
      " [0.00001049 0.00000462 0.00000286 0.9995213  0.00000983 0.00000758\n",
      "  0.00044331]\n",
      " [0.00001276 0.01549015 0.00075975 0.00002243 0.00001604 0.98369143\n",
      "  0.00000745]\n",
      " [0.00001441 0.00000001 0.00000113 0.98982037 0.0019506  0.\n",
      "  0.00821346]\n",
      " [0.00282542 0.00000026 0.00603738 0.98383809 0.00664742 0.00001423\n",
      "  0.0006372 ]\n",
      " [0.00302043 0.00026828 0.08979751 0.0047538  0.89538319 0.00373838\n",
      "  0.00303842]\n",
      " [0.00035746 0.00001028 0.00001755 0.0234884  0.97595716 0.00004814\n",
      "  0.00012101]\n",
      " [0.02255179 0.00011375 0.68930996 0.19783574 0.02318924 0.04486978\n",
      "  0.02212973]\n",
      " [0.82040864 0.00187297 0.08186747 0.00237728 0.08436907 0.00155682\n",
      "  0.00754775]\n",
      " [0.01742212 0.00506783 0.06986278 0.00579955 0.10753439 0.00008882\n",
      "  0.7942245 ]\n",
      " [0.00010552 0.0000332  0.04243628 0.88188122 0.01965168 0.00688041\n",
      "  0.04901168]\n",
      " [0.00730968 0.00000424 0.04839763 0.00542209 0.87386571 0.00001607\n",
      "  0.06498458]\n",
      " [0.81052594 0.00000089 0.00076024 0.16220046 0.02360008 0.00180209\n",
      "  0.0011103 ]\n",
      " [0.00019822 0.00008485 0.00961327 0.00009235 0.94273278 0.00000018\n",
      "  0.04727836]\n",
      " [0.79630486 0.00675277 0.12963402 0.00180286 0.06275732 0.00000829\n",
      "  0.00273989]\n",
      " [0.00091577 0.00000014 0.00000763 0.99895116 0.00000398 0.00000061\n",
      "  0.00012072]\n",
      " [0.00000463 0.00000042 0.00000369 0.99992564 0.00001795 0.00001865\n",
      "  0.00002901]\n",
      " [0.0348263  0.00002599 0.69690169 0.00117486 0.26421304 0.00037143\n",
      "  0.0024867 ]\n",
      " [0.03820127 0.00165581 0.10060018 0.15371882 0.0847445  0.01475305\n",
      "  0.60632636]\n",
      " [0.00191108 0.0013046  0.9135937  0.00306639 0.07432397 0.00570692\n",
      "  0.00009335]\n",
      " [0.28770682 0.00244659 0.06626486 0.00009115 0.00274976 0.00654274\n",
      "  0.63419807]\n",
      " [0.00125082 0.00022757 0.76656292 0.00039234 0.08371362 0.08529733\n",
      "  0.06255539]\n",
      " [0.53862409 0.00113153 0.16780623 0.00341119 0.21163443 0.06442426\n",
      "  0.01296827]\n",
      " [0.00121992 0.00007871 0.00512122 0.00059403 0.04188177 0.01512619\n",
      "  0.93597818]\n",
      " [0.00009365 0.00000075 0.00070904 0.99786    0.00007673 0.00125887\n",
      "  0.00000095]\n",
      " [0.01404029 0.00221648 0.01389562 0.00323336 0.93278964 0.00113774\n",
      "  0.03268687]\n",
      " [0.01842033 0.00490117 0.04459106 0.77532002 0.06571872 0.00297231\n",
      "  0.08807639]\n",
      " [0.00138597 0.00001954 0.15326898 0.01793603 0.19395993 0.42943684\n",
      "  0.20399271]\n",
      " [0.00218338 0.0001536  0.00047663 0.00000932 0.00004325 0.01393148\n",
      "  0.98320235]\n",
      " [0.00248395 0.00452125 0.0426964  0.86196076 0.03637407 0.02861956\n",
      "  0.02334401]\n",
      " [0.15019734 0.00145525 0.01907928 0.0001987  0.07011087 0.40681142\n",
      "  0.35214714]\n",
      " [0.26941642 0.0001854  0.00433626 0.58639498 0.13835592 0.00115882\n",
      "  0.00015219]\n",
      " [0.00000613 0.00000227 0.00000437 0.99679451 0.00000122 0.00000146\n",
      "  0.00319005]\n",
      " [0.00976856 0.04283689 0.88354946 0.00005182 0.0348077  0.02305112\n",
      "  0.00593444]\n",
      " [0.89856261 0.00006867 0.00273324 0.00058613 0.05136495 0.00838854\n",
      "  0.03829587]\n",
      " [0.09658435 0.00001315 0.00641713 0.14520473 0.67391821 0.0005286\n",
      "  0.07733382]\n",
      " [0.14483177 0.00000814 0.01711084 0.00062781 0.83724198 0.00010594\n",
      "  0.00007352]\n",
      " [0.01432925 0.00026519 0.03327501 0.0000084  0.39987057 0.03102828\n",
      "  0.5212233 ]\n",
      " [0.13660814 0.00000003 0.00756255 0.83757684 0.00273538 0.00004588\n",
      "  0.01547118]] (82.684 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.48388320207595825, step = 36500 (16.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04736\n",
      "INFO:tensorflow:loss = 0.3281259834766388, step = 36600 (16.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04705\n",
      "INFO:tensorflow:loss = 0.4176485240459442, step = 36700 (16.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0485\n",
      "INFO:tensorflow:loss = 0.39920005202293396, step = 36800 (16.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04884\n",
      "INFO:tensorflow:loss = 0.3515773415565491, step = 36900 (16.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.01821\n",
      "INFO:tensorflow:probabilities = [[0.00002873 0.00001441 0.15353007 0.58615089 0.03702615 0.22202691\n",
      "  0.00122285]\n",
      " [0.03390221 0.00228298 0.03842675 0.00247126 0.0378513  0.01454172\n",
      "  0.87052377]\n",
      " [0.00036206 0.00434715 0.00178997 0.70982506 0.07987888 0.19216543\n",
      "  0.01163146]\n",
      " [0.0577424  0.00578734 0.00411598 0.33792966 0.00034623 0.00007592\n",
      "  0.59400247]\n",
      " [0.01220683 0.00136545 0.04047063 0.93599243 0.00270012 0.00411903\n",
      "  0.00314551]\n",
      " [0.00000386 0.00556242 0.01778008 0.95168176 0.00115595 0.02308399\n",
      "  0.00073193]\n",
      " [0.00053117 0.0069992  0.99063357 0.00027802 0.00144711 0.00006548\n",
      "  0.00004545]\n",
      " [0.00284375 0.00000478 0.72743641 0.13329479 0.00664783 0.12514243\n",
      "  0.00463001]\n",
      " [0.00055803 0.00000279 0.00539475 0.9887838  0.00338893 0.0004285\n",
      "  0.00144319]\n",
      " [0.99856722 0.00001683 0.00088042 0.00000027 0.00035976 0.00000001\n",
      "  0.00017549]\n",
      " [0.0013609  0.00000279 0.00541403 0.3207325  0.01092534 0.66083525\n",
      "  0.00072919]\n",
      " [0.00860781 0.00063953 0.00202355 0.98488163 0.00226696 0.00146276\n",
      "  0.00011776]\n",
      " [0.97185805 0.00008935 0.01006875 0.00000188 0.01754634 0.00011455\n",
      "  0.00032108]\n",
      " [0.00655889 0.00076893 0.03419802 0.65664939 0.11970582 0.0049299\n",
      "  0.17718906]\n",
      " [0.02864724 0.00056599 0.02110947 0.00009183 0.02688109 0.91822612\n",
      "  0.00447826]\n",
      " [0.00088614 0.00017205 0.00246981 0.00000455 0.00537049 0.00000565\n",
      "  0.99109131]\n",
      " [0.21302116 0.00331258 0.25595391 0.06747997 0.45437768 0.00004316\n",
      "  0.00581155]\n",
      " [0.00057433 0.00023874 0.00000804 0.99911943 0.00004566 0.0000001\n",
      "  0.0000137 ]\n",
      " [0.98344252 0.00058486 0.00722212 0.00002749 0.00402918 0.00000608\n",
      "  0.00468774]\n",
      " [0.00533488 0.00103535 0.71159217 0.00194619 0.07944682 0.02356674\n",
      "  0.17707786]\n",
      " [0.21448591 0.00022548 0.11037612 0.00992895 0.16665822 0.00086135\n",
      "  0.49746397]\n",
      " [0.02979989 0.00000331 0.00475862 0.00056079 0.96336931 0.00001629\n",
      "  0.00149179]\n",
      " [0.00014455 0.00000058 0.07580068 0.00350114 0.00007411 0.92014457\n",
      "  0.00033437]\n",
      " [0.00013566 0.00001679 0.00006025 0.99834821 0.00006119 0.00119692\n",
      "  0.00018098]\n",
      " [0.89059455 0.00000139 0.00356857 0.00001584 0.03665137 0.06869899\n",
      "  0.0004693 ]\n",
      " [0.07567142 0.00449359 0.42502859 0.31258878 0.07960246 0.02676517\n",
      "  0.07584998]\n",
      " [0.00305861 0.00110983 0.5122594  0.00355094 0.05912927 0.00477775\n",
      "  0.4161142 ]\n",
      " [0.91297284 0.00106886 0.02033515 0.00011429 0.0533011  0.0035\n",
      "  0.00870776]\n",
      " [0.00000023 0.00000001 0.00191716 0.00000567 0.00000025 0.99807259\n",
      "  0.0000041 ]\n",
      " [0.57951703 0.00001721 0.07683664 0.00904663 0.3120946  0.00264113\n",
      "  0.01984676]\n",
      " [0.00187667 0.00001258 0.00787073 0.74898468 0.00032154 0.00514494\n",
      "  0.23578886]\n",
      " [0.00004208 0.         0.00040736 0.00000202 0.00000143 0.9995471\n",
      "  0.00000001]\n",
      " [0.00000098 0.00000003 0.99637679 0.00004509 0.00009557 0.00337283\n",
      "  0.00010871]\n",
      " [0.00024133 0.00000653 0.0002546  0.99774123 0.00008381 0.00091704\n",
      "  0.00075547]\n",
      " [0.00002842 0.00000154 0.00085827 0.0000241  0.00031663 0.00000944\n",
      "  0.9987616 ]\n",
      " [0.00000038 0.         0.0000009  0.         0.         0.99999871\n",
      "  0.        ]\n",
      " [0.2971598  0.00017993 0.01991422 0.00001064 0.00446329 0.00000372\n",
      "  0.6782684 ]\n",
      " [0.00006049 0.00000172 0.00002767 0.99715918 0.00074049 0.00000254\n",
      "  0.00200791]\n",
      " [0.08858284 0.00048497 0.01130002 0.0163321  0.86649775 0.00011298\n",
      "  0.01668934]\n",
      " [0.99567877 0.00205672 0.00057767 0.00000034 0.00049974 0.0003912\n",
      "  0.00079557]\n",
      " [0.04843754 0.01492079 0.07020846 0.83869607 0.01092631 0.00760194\n",
      "  0.00920888]\n",
      " [0.1210941  0.00042511 0.23749986 0.00061534 0.56805762 0.0696789\n",
      "  0.00262908]\n",
      " [0.87256407 0.00000797 0.02230066 0.01338856 0.09108633 0.00003047\n",
      "  0.00062194]\n",
      " [0.08741106 0.00023901 0.023355   0.86221121 0.00396957 0.0000229\n",
      "  0.02279124]\n",
      " [0.03560689 0.00015171 0.44962033 0.06077187 0.14697953 0.00490976\n",
      "  0.30195991]\n",
      " [0.01653123 0.0676098  0.09820488 0.00079353 0.00237215 0.81338838\n",
      "  0.00110003]\n",
      " [0.0001145  0.00006655 0.87459314 0.06492157 0.04196463 0.00068781\n",
      "  0.01765181]\n",
      " [0.00553623 0.00049173 0.00043626 0.93489855 0.00499173 0.00640697\n",
      "  0.04723853]\n",
      " [0.00170107 0.00004772 0.01146519 0.51905649 0.00433894 0.02245847\n",
      "  0.44093212]\n",
      " [0.01306359 0.00026681 0.0088048  0.78523742 0.00901871 0.0015199\n",
      "  0.18208877]] (82.755 sec)\n",
      "INFO:tensorflow:loss = 0.3596954941749573, step = 37000 (16.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.00764\n",
      "INFO:tensorflow:loss = 0.3419640362262726, step = 37100 (16.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02844\n",
      "INFO:tensorflow:loss = 0.39610809087753296, step = 37200 (16.600 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 37229 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 5.80094\n",
      "INFO:tensorflow:loss = 0.27316638827323914, step = 37300 (17.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.00127\n",
      "INFO:tensorflow:loss = 0.4274369776248932, step = 37400 (16.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04599\n",
      "INFO:tensorflow:probabilities = [[0.10388198 0.09368542 0.61764142 0.00252484 0.18041517 0.00064412\n",
      "  0.00120704]\n",
      " [0.01968717 0.02071412 0.19191943 0.00548297 0.01496097 0.08196569\n",
      "  0.66526965]\n",
      " [0.01152589 0.00015682 0.04408686 0.00362612 0.04624352 0.00010325\n",
      "  0.89425754]\n",
      " [0.00017162 0.00000155 0.03115774 0.02703294 0.01523022 0.01909232\n",
      "  0.90731361]\n",
      " [0.00064574 0.00000035 0.0005551  0.00000055 0.00237358 0.00011837\n",
      "  0.99630632]\n",
      " [0.00033715 0.00000003 0.00009993 0.00380362 0.96046881 0.00000215\n",
      "  0.03528832]\n",
      " [0.00310231 0.00002137 0.00298017 0.00238601 0.9468599  0.00000271\n",
      "  0.04464752]\n",
      " [0.00276378 0.00057395 0.00217518 0.00071182 0.00124455 0.99229115\n",
      "  0.00023958]\n",
      " [0.08492357 0.00012901 0.00014297 0.00380133 0.6968392  0.00000111\n",
      "  0.21416281]\n",
      " [0.00512059 0.00020857 0.00608097 0.00040308 0.00336074 0.98219906\n",
      "  0.00262698]\n",
      " [0.00661826 0.00001425 0.98531053 0.00000373 0.00008589 0.00460189\n",
      "  0.00336546]\n",
      " [0.03076718 0.00001559 0.0131097  0.00032096 0.14348051 0.05858687\n",
      "  0.7537192 ]\n",
      " [0.00900041 0.00022737 0.04867797 0.0005223  0.04360768 0.00107227\n",
      "  0.896892  ]\n",
      " [0.00022455 0.00000021 0.0000125  0.99971709 0.0000033  0.00000002\n",
      "  0.00004233]\n",
      " [0.02247147 0.00034685 0.00171693 0.00800097 0.11165135 0.00048056\n",
      "  0.85533187]\n",
      " [0.88402201 0.03170728 0.02372994 0.01056876 0.03505366 0.00004035\n",
      "  0.01487801]\n",
      " [0.74356686 0.00018788 0.05462458 0.0419199  0.01117669 0.00000698\n",
      "  0.1485171 ]\n",
      " [0.14349496 0.00005059 0.00649997 0.82577527 0.02363131 0.0002111\n",
      "  0.0003368 ]\n",
      " [0.00033277 0.00000913 0.93523206 0.0071849  0.00365535 0.04081598\n",
      "  0.01276981]\n",
      " [0.00002592 0.00000066 0.0000348  0.99324321 0.00499421 0.00152185\n",
      "  0.00017935]\n",
      " [0.13144817 0.00638005 0.00303385 0.81688123 0.01429953 0.00003282\n",
      "  0.02792434]\n",
      " [0.00025813 0.00000207 0.00192967 0.0000735  0.99756623 0.00000003\n",
      "  0.00017038]\n",
      " [0.0002792  0.00001289 0.00000245 0.99961223 0.00001282 0.00005315\n",
      "  0.00002726]\n",
      " [0.02615445 0.00033886 0.02510704 0.01713137 0.09183812 0.30192895\n",
      "  0.53750122]\n",
      " [0.06534418 0.00037541 0.00502176 0.85038584 0.05176003 0.00278335\n",
      "  0.02432942]\n",
      " [0.96114508 0.00000493 0.00145094 0.00197256 0.0015912  0.00513888\n",
      "  0.0286964 ]\n",
      " [0.02682819 0.00202705 0.10572014 0.05776755 0.47094635 0.00095529\n",
      "  0.33575543]\n",
      " [0.22612557 0.00677913 0.00406947 0.71750057 0.00095267 0.04376244\n",
      "  0.00081015]\n",
      " [0.59860424 0.00000028 0.01005781 0.23050807 0.00098267 0.00000548\n",
      "  0.15984144]\n",
      " [0.00064247 0.00000186 0.00001635 0.99274274 0.0006705  0.0000014\n",
      "  0.00592467]\n",
      " [0.02175975 0.00000359 0.00106821 0.97692375 0.00001316 0.0000282\n",
      "  0.00020334]\n",
      " [0.00066033 0.00048382 0.52169467 0.00000763 0.00032959 0.4760692\n",
      "  0.00075475]\n",
      " [0.00725489 0.00522675 0.00990437 0.00589008 0.95335325 0.0089983\n",
      "  0.00937237]\n",
      " [0.08509934 0.00213713 0.67840001 0.00074186 0.19730983 0.0004691\n",
      "  0.03584272]\n",
      " [0.00408323 0.0000085  0.00181329 0.0467515  0.91896456 0.00958422\n",
      "  0.0187947 ]\n",
      " [0.00105293 0.00126445 0.00142451 0.94327921 0.0026864  0.04569495\n",
      "  0.00459756]\n",
      " [0.00438313 0.00124077 0.00156293 0.00003481 0.04533598 0.00029383\n",
      "  0.94714854]\n",
      " [0.00425535 0.00008006 0.01394681 0.00051969 0.50114054 0.00619997\n",
      "  0.47385759]\n",
      " [0.01221578 0.000001   0.96380833 0.00129584 0.00516747 0.00294856\n",
      "  0.01456302]\n",
      " [0.00025149 0.00349044 0.00293291 0.00020278 0.97967341 0.00006199\n",
      "  0.01338698]\n",
      " [0.0000155  0.00005479 0.00008536 0.99603538 0.00158299 0.0006178\n",
      "  0.00160817]\n",
      " [0.00004362 0.00001882 0.00092151 0.00270227 0.00370218 0.00002451\n",
      "  0.99258708]\n",
      " [0.00002154 0.00000066 0.00000529 0.99978962 0.00001981 0.00000392\n",
      "  0.00015918]\n",
      " [0.12161721 0.00033201 0.32837326 0.00529734 0.49330711 0.00068624\n",
      "  0.05038683]\n",
      " [0.17631217 0.00072441 0.00442802 0.04994394 0.7516072  0.01666929\n",
      "  0.00031498]\n",
      " [0.00003945 0.00000032 0.01951169 0.00001382 0.94670968 0.\n",
      "  0.03372504]\n",
      " [0.00001083 0.00000001 0.00000138 0.99996243 0.000005   0.00000041\n",
      "  0.00001994]\n",
      " [0.02191551 0.03353168 0.02877191 0.00001409 0.79131135 0.00005607\n",
      "  0.12439939]\n",
      " [0.47980537 0.00146077 0.04009178 0.0622412  0.26320014 0.06326428\n",
      "  0.08993645]\n",
      " [0.00322404 0.00038469 0.02507008 0.94761849 0.0135782  0.000006\n",
      "  0.01011851]] (83.674 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.35936567187309265, step = 37500 (16.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03979\n",
      "INFO:tensorflow:loss = 0.4188980758190155, step = 37600 (16.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04897\n",
      "INFO:tensorflow:loss = 0.344603031873703, step = 37700 (16.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0408\n",
      "INFO:tensorflow:loss = 0.5343884229660034, step = 37800 (16.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04913\n",
      "INFO:tensorflow:loss = 0.41026851534843445, step = 37900 (16.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05175\n",
      "INFO:tensorflow:probabilities = [[0.00096047 0.00015913 0.02249715 0.90389557 0.02491357 0.00000099\n",
      "  0.04757312]\n",
      " [0.0001641  0.00005377 0.00521493 0.00031842 0.994035   0.00001311\n",
      "  0.00020067]\n",
      " [0.00053326 0.         0.00000029 0.8809978  0.00090315 0.\n",
      "  0.1175655 ]\n",
      " [0.00624548 0.0244159  0.00379015 0.00148027 0.93497617 0.00017482\n",
      "  0.02891721]\n",
      " [0.0119288  0.00642905 0.02885388 0.03594311 0.00866546 0.00067346\n",
      "  0.90750624]\n",
      " [0.02738612 0.04906517 0.06947439 0.48386396 0.17764964 0.17099426\n",
      "  0.02156646]\n",
      " [0.49583918 0.00001496 0.09215049 0.05526042 0.32707704 0.00002517\n",
      "  0.02963274]\n",
      " [0.00007585 0.00000104 0.00050608 0.99627818 0.00005532 0.00018144\n",
      "  0.00290209]\n",
      " [0.00713163 0.39785352 0.01494051 0.30781406 0.02890092 0.00000619\n",
      "  0.24335317]\n",
      " [0.00051365 0.00063807 0.61702061 0.00033145 0.00050058 0.37612128\n",
      "  0.00487437]\n",
      " [0.05896486 0.0015626  0.1334047  0.00000095 0.66734137 0.00000168\n",
      "  0.13872383]\n",
      " [0.05293175 0.0002683  0.00422536 0.01579811 0.08095239 0.00081311\n",
      "  0.84501097]\n",
      " [0.00304164 0.00005397 0.00241457 0.01164578 0.00426785 0.00028056\n",
      "  0.97829562]\n",
      " [0.00000001 0.00000086 0.00210386 0.00221152 0.0000013  0.99566729\n",
      "  0.00001514]\n",
      " [0.96660943 0.00020366 0.01775871 0.00001795 0.01529516 0.0000008\n",
      "  0.00011427]\n",
      " [0.16294577 0.00000615 0.0086559  0.00016479 0.82822207 0.00000371\n",
      "  0.00000163]\n",
      " [0.00172739 0.00007245 0.27479751 0.0020824  0.01860248 0.70224694\n",
      "  0.00047082]\n",
      " [0.00000548 0.         0.00000593 0.99998334 0.00000272 0.00000023\n",
      "  0.00000228]\n",
      " [0.00055081 0.00043448 0.00027207 0.99284196 0.00033762 0.00026217\n",
      "  0.0053009 ]\n",
      " [0.00085609 0.00000008 0.00022346 0.6273246  0.10232613 0.00004348\n",
      "  0.26922617]\n",
      " [0.00016749 0.00041253 0.01223667 0.00125383 0.00074803 0.98455015\n",
      "  0.0006313 ]\n",
      " [0.00491352 0.         0.00004362 0.00710974 0.00054132 0.0000405\n",
      "  0.98735131]\n",
      " [0.00170392 0.00001142 0.00012028 0.00000126 0.04136029 0.00108474\n",
      "  0.9557181 ]\n",
      " [0.00132725 0.00009338 0.00039547 0.91832313 0.07590641 0.00001335\n",
      "  0.00394102]\n",
      " [0.00362661 0.00009912 0.4219669  0.29887494 0.26449943 0.00016394\n",
      "  0.01076906]\n",
      " [0.08171231 0.03696921 0.1703548  0.0442314  0.10364124 0.01069783\n",
      "  0.55239322]\n",
      " [0.00306337 0.00001232 0.03165292 0.03433819 0.90601097 0.00000999\n",
      "  0.02491222]\n",
      " [0.00079793 0.04694859 0.00851028 0.0034878  0.85514443 0.00188745\n",
      "  0.08322351]\n",
      " [0.99516299 0.00003801 0.00150216 0.00024954 0.00206151 0.00002377\n",
      "  0.00096202]\n",
      " [0.03670123 0.00004877 0.00499635 0.00116159 0.9156591  0.00001953\n",
      "  0.04141343]\n",
      " [0.01256199 0.00006457 0.00039272 0.98250893 0.0008734  0.00015951\n",
      "  0.00343887]\n",
      " [0.00180063 0.00408046 0.01745722 0.90463572 0.00538859 0.06436298\n",
      "  0.00227441]\n",
      " [0.00422181 0.00000198 0.0004934  0.02909223 0.68233544 0.00083551\n",
      "  0.28301963]\n",
      " [0.00183275 0.000025   0.0000596  0.00003683 0.00004246 0.00003454\n",
      "  0.99796883]\n",
      " [0.00000065 0.00000315 0.00057495 0.00000049 0.0000037  0.9994168\n",
      "  0.00000027]\n",
      " [0.85018992 0.0018164  0.12564682 0.01439121 0.00158203 0.00423378\n",
      "  0.00213986]\n",
      " [0.00001506 0.00000227 0.00006899 0.99969656 0.00001229 0.00004219\n",
      "  0.00016264]\n",
      " [0.00641986 0.0000006  0.00000636 0.00000003 0.99356739 0.\n",
      "  0.00000577]\n",
      " [0.09186515 0.07750728 0.06761647 0.00000177 0.7333386  0.0000028\n",
      "  0.02966794]\n",
      " [0.07795995 0.00033471 0.00142595 0.73128288 0.06143503 0.03520453\n",
      "  0.09235695]\n",
      " [0.0220058  0.         0.03216389 0.00065479 0.01665847 0.02152014\n",
      "  0.9069969 ]\n",
      " [0.00009609 0.00000074 0.00001981 0.99683163 0.0012731  0.00036696\n",
      "  0.00141167]\n",
      " [0.22937221 0.00046789 0.10399788 0.10655842 0.08323106 0.04547877\n",
      "  0.43089377]\n",
      " [0.12553764 0.00018985 0.01279433 0.76884982 0.08820192 0.00002114\n",
      "  0.0044053 ]\n",
      " [0.00498267 0.000065   0.02226612 0.00020376 0.97021196 0.00003819\n",
      "  0.00223229]\n",
      " [0.00825925 0.00014472 0.00299756 0.0071942  0.01446667 0.00000105\n",
      "  0.96693656]\n",
      " [0.00044248 0.00000027 0.02766743 0.00085564 0.97093324 0.00000111\n",
      "  0.00009983]\n",
      " [0.72118112 0.00339786 0.0753723  0.09170773 0.01928529 0.00773536\n",
      "  0.08132035]\n",
      " [0.2592813  0.00696777 0.06667445 0.0038201  0.0909083  0.00087327\n",
      "  0.57147481]\n",
      " [0.9983017  0.00002234 0.00014415 0.00000141 0.00030314 0.00000033\n",
      "  0.00122694]] (82.710 sec)\n",
      "INFO:tensorflow:loss = 0.34504690766334534, step = 38000 (16.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04199\n",
      "INFO:tensorflow:loss = 0.39362776279449463, step = 38100 (16.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04839\n",
      "INFO:tensorflow:loss = 0.37713244557380676, step = 38200 (16.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03707\n",
      "INFO:tensorflow:loss = 0.29989489912986755, step = 38300 (16.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03793\n",
      "INFO:tensorflow:loss = 0.5793156027793884, step = 38400 (16.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04209\n",
      "INFO:tensorflow:probabilities = [[0.08144237 0.00004724 0.00077162 0.83709985 0.02187016 0.00203784\n",
      "  0.05673093]\n",
      " [0.00359404 0.00000009 0.0002888  0.99611141 0.00000554 0.0000001\n",
      "  0.00000003]\n",
      " [0.17572498 0.00849222 0.54978264 0.01633929 0.21133868 0.00827666\n",
      "  0.03004554]\n",
      " [0.06574178 0.00060736 0.07680406 0.13679428 0.48618028 0.01352145\n",
      "  0.22035079]\n",
      " [0.98819142 0.         0.00158773 0.00192256 0.00798581 0.00000003\n",
      "  0.00031244]\n",
      " [0.05801878 0.00000137 0.00378548 0.00005723 0.02928237 0.00066609\n",
      "  0.90818868]\n",
      " [0.00175586 0.00107918 0.00379511 0.93673854 0.00566613 0.00031243\n",
      "  0.05065274]\n",
      " [0.40890816 0.00010058 0.013804   0.39792    0.17807705 0.0000498\n",
      "  0.00114041]\n",
      " [0.00218478 0.00026843 0.03175416 0.55662026 0.03660478 0.00385173\n",
      "  0.36871585]\n",
      " [0.01197566 0.00080887 0.00009917 0.93982807 0.00915606 0.00081213\n",
      "  0.03732003]\n",
      " [0.00066897 0.00000131 0.00161564 0.00000023 0.51110757 0.00000006\n",
      "  0.48660622]\n",
      " [0.00075007 0.0000103  0.01417175 0.0076624  0.00430061 0.0204518\n",
      "  0.95265307]\n",
      " [0.08489282 0.00002484 0.00004372 0.65124459 0.26242273 0.00020786\n",
      "  0.00116343]\n",
      " [0.02184575 0.00012576 0.00135818 0.97575349 0.00040235 0.00050374\n",
      "  0.00001073]\n",
      " [0.61099262 0.00049665 0.00044334 0.00025786 0.00115149 0.00479553\n",
      "  0.38186251]\n",
      " [0.0000055  0.00000001 0.00107094 0.00899128 0.00000007 0.98992563\n",
      "  0.00000656]\n",
      " [0.01861576 0.00000103 0.02341303 0.00000206 0.13024498 0.78072333\n",
      "  0.04699981]\n",
      " [0.00018936 0.00000308 0.00000038 0.99973231 0.00003508 0.0000058\n",
      "  0.000034  ]\n",
      " [0.00365176 0.00000088 0.00229036 0.00378838 0.00003706 0.98790094\n",
      "  0.00233061]\n",
      " [0.10955283 0.0002145  0.33406824 0.30841335 0.23948537 0.00741634\n",
      "  0.00084936]\n",
      " [0.01841344 0.00008659 0.36407223 0.04084851 0.06730485 0.04413231\n",
      "  0.46514207]\n",
      " [0.00332909 0.0000075  0.39212858 0.00008627 0.0046405  0.05035919\n",
      "  0.54944886]\n",
      " [0.00004623 0.         0.00000068 0.00015671 0.00000005 0.99977877\n",
      "  0.00001756]\n",
      " [0.0176838  0.00000061 0.00004208 0.92891482 0.00000067 0.00340083\n",
      "  0.04995719]\n",
      " [0.00352745 0.00003504 0.035826   0.80386767 0.00027585 0.00087868\n",
      "  0.15558931]\n",
      " [0.02855659 0.0002212  0.00303248 0.00158481 0.1325807  0.00027798\n",
      "  0.83374624]\n",
      " [0.03210191 0.0004621  0.01801164 0.00092818 0.00268592 0.00160927\n",
      "  0.94420099]\n",
      " [0.00001823 0.00000026 0.42527939 0.00089199 0.00002291 0.57323136\n",
      "  0.00055585]\n",
      " [0.0000027  0.         0.99893256 0.00000052 0.00000019 0.00106308\n",
      "  0.00000096]\n",
      " [0.00522898 0.00003123 0.93438272 0.00091113 0.00857794 0.03091484\n",
      "  0.01995314]\n",
      " [0.06678861 0.00009444 0.02310605 0.00205576 0.02341406 0.00786211\n",
      "  0.87667897]\n",
      " [0.02288896 0.0003083  0.91976436 0.00079805 0.0105525  0.00773374\n",
      "  0.03795409]\n",
      " [0.00276693 0.0132792  0.97687251 0.00002573 0.00634141 0.00044249\n",
      "  0.00027172]\n",
      " [0.11839254 0.00002862 0.0159602  0.00052494 0.7760688  0.00819587\n",
      "  0.08082903]\n",
      " [0.98800171 0.00000009 0.00048388 0.00000102 0.00377263 0.00000003\n",
      "  0.00774064]\n",
      " [0.40943139 0.00551845 0.04961856 0.01516689 0.42335608 0.00479539\n",
      "  0.09211325]\n",
      " [0.02326032 0.00427379 0.07781828 0.06387869 0.70268032 0.04669952\n",
      "  0.08138907]\n",
      " [0.68103103 0.0000163  0.12163335 0.01348643 0.17869399 0.00000111\n",
      "  0.00513779]\n",
      " [0.00070306 0.00002323 0.01869699 0.00001423 0.00007653 0.98044167\n",
      "  0.00004428]\n",
      " [0.00030929 0.0007054  0.0063935  0.97594045 0.01308574 0.00002306\n",
      "  0.00354257]\n",
      " [0.0093039  0.0005694  0.00013255 0.98691613 0.00254569 0.00017601\n",
      "  0.00035632]\n",
      " [0.07264614 0.00021225 0.36510728 0.019883   0.52815669 0.00852645\n",
      "  0.0054682 ]\n",
      " [0.00543988 0.00000097 0.04994711 0.06836449 0.86495411 0.00276243\n",
      "  0.008531  ]\n",
      " [0.02376692 0.00011978 0.18327913 0.00557144 0.03102738 0.00166924\n",
      "  0.75456611]\n",
      " [0.00021426 0.00017587 0.74759156 0.04621582 0.19609897 0.00275466\n",
      "  0.00694885]\n",
      " [0.00008369 0.00016704 0.99737419 0.         0.00000014 0.00002933\n",
      "  0.00234562]\n",
      " [0.00051305 0.00000003 0.02429913 0.00000715 0.0000927  0.97506776\n",
      "  0.00002018]\n",
      " [0.00004669 0.00000242 0.00005616 0.99972373 0.00008096 0.00000002\n",
      "  0.00009003]\n",
      " [0.00000025 0.         0.00009681 0.00000411 0.00000059 0.99977406\n",
      "  0.00012417]\n",
      " [0.02984481 0.00007134 0.00177278 0.38759133 0.07690803 0.00716168\n",
      "  0.49665003]] (82.748 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.38053077459335327, step = 38500 (16.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03877\n",
      "INFO:tensorflow:loss = 0.6203258633613586, step = 38600 (16.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03594\n",
      "INFO:tensorflow:loss = 0.3728092610836029, step = 38700 (16.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02892\n",
      "INFO:tensorflow:loss = 0.46419280767440796, step = 38800 (16.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0185\n",
      "INFO:tensorflow:loss = 0.22436125576496124, step = 38900 (16.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.02875\n",
      "INFO:tensorflow:probabilities = [[0.00857755 0.00123283 0.86725538 0.00149923 0.00727723 0.03841258\n",
      "  0.0757452 ]\n",
      " [0.10307246 0.00007601 0.00529834 0.7323901  0.00659222 0.00754703\n",
      "  0.14502384]\n",
      " [0.00019879 0.00000016 0.00004913 0.0000006  0.99711444 0.00015669\n",
      "  0.00248019]\n",
      " [0.00495525 0.00000005 0.00013949 0.98828904 0.00001192 0.00016215\n",
      "  0.00644211]\n",
      " [0.23719645 0.01446242 0.16083432 0.16885415 0.40122669 0.00273998\n",
      "  0.01468599]\n",
      " [0.00013949 0.00160822 0.00105521 0.9767787  0.00235328 0.00035981\n",
      "  0.01770529]\n",
      " [0.824055   0.02352526 0.04935349 0.04041628 0.05969083 0.00107128\n",
      "  0.00188787]\n",
      " [0.26826801 0.00000002 0.02919205 0.00842844 0.00162945 0.00000086\n",
      "  0.69248117]\n",
      " [0.5128409  0.00019962 0.00108797 0.00826937 0.46464847 0.0000095\n",
      "  0.01294417]\n",
      " [0.00010689 0.00000034 0.40888468 0.00009101 0.0000236  0.59086829\n",
      "  0.00002519]\n",
      " [0.03304859 0.01084356 0.90333006 0.02284812 0.02071608 0.00214789\n",
      "  0.0070657 ]\n",
      " [0.00279047 0.00001154 0.95787137 0.00003152 0.03522765 0.00087643\n",
      "  0.00319102]\n",
      " [0.         0.         0.00000917 0.99998073 0.00000003 0.00000846\n",
      "  0.00000161]\n",
      " [0.00001618 0.00000354 0.12468486 0.00013664 0.86614281 0.00002816\n",
      "  0.00898781]\n",
      " [0.66737691 0.00053632 0.25157385 0.00461844 0.02230135 0.00029024\n",
      "  0.05330287]\n",
      " [0.02926627 0.00062249 0.01131102 0.01575177 0.09361644 0.00400367\n",
      "  0.84542833]\n",
      " [0.00650929 0.00017607 0.00105834 0.0211294  0.00141038 0.0015551\n",
      "  0.96816142]\n",
      " [0.00021601 0.00000002 0.00003803 0.99974508 0.00000072 0.00000008\n",
      "  0.00000006]\n",
      " [0.07027766 0.02766443 0.62949236 0.00000158 0.02780729 0.0109733\n",
      "  0.23378339]\n",
      " [0.82750723 0.00462334 0.00295092 0.01867985 0.0555362  0.00343023\n",
      "  0.08727222]\n",
      " [0.02847324 0.00029658 0.45088272 0.04677554 0.02290393 0.39610037\n",
      "  0.05456762]\n",
      " [0.0006141  0.00039176 0.0924939  0.11279253 0.76790288 0.00002578\n",
      "  0.02577904]\n",
      " [0.02055578 0.00030565 0.28406364 0.00157485 0.16504619 0.00525315\n",
      "  0.52320073]\n",
      " [0.00762248 0.0000009  0.00002101 0.00000005 0.98831674 0.0000413\n",
      "  0.00399753]\n",
      " [0.00000891 0.00000179 0.00018973 0.99967823 0.00001661 0.00000008\n",
      "  0.00010466]\n",
      " [0.0000178  0.         0.00244327 0.0000001  0.78940119 0.00000001\n",
      "  0.20813761]\n",
      " [0.00292839 0.00000003 0.98598638 0.00027283 0.01033278 0.00032174\n",
      "  0.00015786]\n",
      " [0.9993882  0.         0.00008777 0.00021714 0.00030439 0.00000009\n",
      "  0.00000241]\n",
      " [0.02446144 0.00482026 0.19374554 0.00175642 0.620737   0.00608841\n",
      "  0.14839093]\n",
      " [0.66137358 0.00026875 0.21048337 0.0167778  0.09806227 0.01279667\n",
      "  0.00023757]\n",
      " [0.00936356 0.00002945 0.00042883 0.36207333 0.00371722 0.01450492\n",
      "  0.60988268]\n",
      " [0.00241896 0.0001577  0.00061002 0.76456121 0.00014126 0.00027639\n",
      "  0.23183445]\n",
      " [0.00161136 0.00001223 0.00339692 0.06551934 0.06623297 0.0001185\n",
      "  0.86310868]\n",
      " [0.00130055 0.00004693 0.00310409 0.00000006 0.9862924  0.0000017\n",
      "  0.00925427]\n",
      " [0.00003325 0.00000003 0.00000169 0.99989198 0.00000182 0.\n",
      "  0.00007121]\n",
      " [0.99935483 0.00003401 0.00010845 0.00000001 0.00002834 0.00000218\n",
      "  0.00047218]\n",
      " [0.00110661 0.0002472  0.00010792 0.00013695 0.00367285 0.00000351\n",
      "  0.99472496]\n",
      " [0.08449496 0.00016332 0.00592941 0.01303156 0.00871221 0.00000178\n",
      "  0.88766676]\n",
      " [0.57903577 0.00109784 0.28216233 0.00081003 0.0414867  0.03145605\n",
      "  0.06395128]\n",
      " [0.0930782  0.00034335 0.51476029 0.00472347 0.08017182 0.02547383\n",
      "  0.28144903]\n",
      " [0.00136567 0.00000043 0.00000345 0.00991822 0.00017564 0.00034242\n",
      "  0.98819418]\n",
      " [0.00037557 0.00000774 0.1140737  0.17475653 0.04722037 0.6552123\n",
      "  0.0083538 ]\n",
      " [0.01703738 0.00000003 0.00520128 0.12963842 0.00341585 0.0499861\n",
      "  0.79472095]\n",
      " [0.00150965 0.0000017  0.00007485 0.00003804 0.00397149 0.00000356\n",
      "  0.99440071]\n",
      " [0.00024757 0.00048948 0.02374134 0.00011654 0.21727472 0.00011623\n",
      "  0.7580141 ]\n",
      " [0.01488371 0.02327864 0.02751408 0.00386213 0.92733179 0.00009038\n",
      "  0.00303926]\n",
      " [0.02922467 0.00102407 0.0306279  0.34960931 0.00543342 0.02322336\n",
      "  0.56085727]\n",
      " [0.04840659 0.00378066 0.03112212 0.00074168 0.04547735 0.83423649\n",
      "  0.03623511]\n",
      " [0.04048587 0.00162027 0.06211913 0.01187317 0.84951685 0.00001421\n",
      "  0.03437049]\n",
      " [0.05828165 0.0019992  0.0072268  0.91360119 0.0124502  0.00001715\n",
      "  0.00642381]] (82.918 sec)\n",
      "INFO:tensorflow:loss = 0.45467084646224976, step = 39000 (16.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.01519\n",
      "INFO:tensorflow:loss = 0.3968599736690521, step = 39100 (16.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03803\n",
      "INFO:tensorflow:loss = 0.37576696276664734, step = 39200 (16.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.04487\n",
      "INFO:tensorflow:loss = 0.19688823819160461, step = 39300 (16.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03297\n",
      "INFO:tensorflow:loss = 0.39771392941474915, step = 39400 (16.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03246\n",
      "INFO:tensorflow:probabilities = [[0.00017419 0.00000042 0.99544883 0.00083683 0.00257918 0.00019652\n",
      "  0.00076404]\n",
      " [0.00532922 0.00000821 0.00017592 0.99346798 0.00027431 0.00003771\n",
      "  0.00070665]\n",
      " [0.05663358 0.01247613 0.43682978 0.19381008 0.16823952 0.05760832\n",
      "  0.07440258]\n",
      " [0.02568948 0.00144118 0.33114757 0.00016605 0.53571177 0.02980611\n",
      "  0.07603784]\n",
      " [0.00087166 0.00066914 0.00005521 0.88122952 0.00661123 0.00063206\n",
      "  0.10993118]\n",
      " [0.00314083 0.00542673 0.03169987 0.00103613 0.44143094 0.06702851\n",
      "  0.45023698]\n",
      " [0.00000891 0.00000004 0.00000008 0.99996359 0.00000029 0.\n",
      "  0.0000271 ]\n",
      " [0.00239776 0.00000047 0.02177442 0.00009003 0.89609276 0.02725707\n",
      "  0.05238748]\n",
      " [0.00450348 0.00005289 0.77587695 0.00010098 0.04940037 0.03912972\n",
      "  0.13093561]\n",
      " [0.00000003 0.         0.00000029 0.00000001 0.00000302 0.99999605\n",
      "  0.0000006 ]\n",
      " [0.00194626 0.00000713 0.17704869 0.10705712 0.04829365 0.00850646\n",
      "  0.6571407 ]\n",
      " [0.00174246 0.00000001 0.00000168 0.99756694 0.00061926 0.00001204\n",
      "  0.00005761]\n",
      " [0.01609676 0.00718004 0.09946057 0.00322864 0.007899   0.01170938\n",
      "  0.8544256 ]\n",
      " [0.00232227 0.00014888 0.1900923  0.00040114 0.80322179 0.00344903\n",
      "  0.0003646 ]\n",
      " [0.00430506 0.00042272 0.0011752  0.95049906 0.00086314 0.04131692\n",
      "  0.00141792]\n",
      " [0.01106179 0.24698191 0.2551171  0.00312111 0.34342712 0.08693701\n",
      "  0.05335395]\n",
      " [0.00006847 0.00000022 0.0041491  0.99552609 0.00000612 0.00024199\n",
      "  0.00000801]\n",
      " [0.0029987  0.00014095 0.00001275 0.99570586 0.00006678 0.00000415\n",
      "  0.00107081]\n",
      " [0.00063515 0.00006901 0.00005325 0.00140561 0.98151553 0.00001116\n",
      "  0.01631027]\n",
      " [0.0003235  0.000857   0.00113041 0.02221959 0.00375108 0.00005472\n",
      "  0.9716637 ]\n",
      " [0.99962115 0.00000444 0.00031445 0.0000039  0.00004706 0.00000804\n",
      "  0.00000097]\n",
      " [0.00000477 0.00000005 0.00000022 0.99982157 0.00000402 0.00000087\n",
      "  0.0001685 ]\n",
      " [0.00002988 0.00002371 0.03053978 0.00025807 0.00061078 0.95692093\n",
      "  0.01161685]\n",
      " [0.02287749 0.00001043 0.00424442 0.54008287 0.0123965  0.00036842\n",
      "  0.42001985]\n",
      " [0.00030629 0.00000608 0.0069519  0.99037124 0.0013248  0.00000485\n",
      "  0.00103485]\n",
      " [0.00023358 0.00007382 0.01127674 0.00036855 0.00000599 0.9556083\n",
      "  0.03243303]\n",
      " [0.01487917 0.00000335 0.00000237 0.98432048 0.00005933 0.00066156\n",
      "  0.00007375]\n",
      " [0.00111064 0.00045631 0.00228209 0.882126   0.00059644 0.00096946\n",
      "  0.11245908]\n",
      " [0.00369898 0.00010038 0.0002128  0.90638365 0.01276484 0.00003177\n",
      "  0.07680758]\n",
      " [0.01126292 0.00002119 0.00004597 0.54326913 0.01637088 0.00000063\n",
      "  0.42902929]\n",
      " [0.00062475 0.00072018 0.00363135 0.00194145 0.02167041 0.00000115\n",
      "  0.97141069]\n",
      " [0.10276788 0.00001417 0.82842095 0.0004753  0.00064406 0.06752637\n",
      "  0.00015126]\n",
      " [0.00082697 0.01876588 0.00053866 0.00246362 0.74186888 0.00000272\n",
      "  0.23553327]\n",
      " [0.00000356 0.         0.01185297 0.         0.00000143 0.98810735\n",
      "  0.00003469]\n",
      " [0.00000229 0.         0.00002604 0.00000098 0.00000001 0.99997066\n",
      "  0.00000001]\n",
      " [0.00558544 0.00011196 0.16174338 0.00037117 0.05266534 0.01300216\n",
      "  0.76652055]\n",
      " [0.24285416 0.0000293  0.70088251 0.00110683 0.0491616  0.00118813\n",
      "  0.00477747]\n",
      " [0.24694152 0.0000972  0.30041773 0.00000368 0.05988306 0.00079666\n",
      "  0.39186014]\n",
      " [0.00025137 0.00003042 0.00077959 0.98692643 0.00140722 0.01046168\n",
      "  0.00014329]\n",
      " [0.00934408 0.00046365 0.11912936 0.00029664 0.79392117 0.001397\n",
      "  0.07544811]\n",
      " [0.08135777 0.00001866 0.01863871 0.01258732 0.0323387  0.01868406\n",
      "  0.83637477]\n",
      " [0.00185037 0.00021896 0.37488075 0.09070307 0.0587805  0.4126461\n",
      "  0.06092027]\n",
      " [0.96327408 0.         0.00079275 0.00013991 0.03469643 0.00109682\n",
      "  0.        ]\n",
      " [0.80051206 0.00024557 0.01662637 0.05909193 0.08309519 0.00084032\n",
      "  0.03958855]\n",
      " [0.02285848 0.0000083  0.04758333 0.00001745 0.91437801 0.00055501\n",
      "  0.01459941]\n",
      " [0.98716747 0.00000136 0.00005614 0.01117865 0.00005796 0.00000785\n",
      "  0.00153056]\n",
      " [0.00032216 0.00001595 0.00027648 0.96853613 0.01953881 0.00005783\n",
      "  0.01125264]\n",
      " [0.00000156 0.         0.00037555 0.99087003 0.00019479 0.00589914\n",
      "  0.00265893]\n",
      " [0.00867616 0.00000014 0.01568581 0.00828472 0.00002555 0.96692785\n",
      "  0.00039978]\n",
      " [0.00630239 0.00013025 0.07180918 0.01202078 0.68537414 0.00197314\n",
      "  0.22239012]] (82.881 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.33043453097343445, step = 39500 (16.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03312\n",
      "INFO:tensorflow:loss = 0.316045343875885, step = 39600 (16.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03088\n",
      "INFO:tensorflow:loss = 0.41265836358070374, step = 39700 (16.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.01635\n",
      "INFO:tensorflow:loss = 0.37061312794685364, step = 39800 (16.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03341\n",
      "INFO:tensorflow:loss = 0.3838799297809601, step = 39900 (16.574 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.32113170623779297.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1a0428e6dd8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  # Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_x},\n",
    "    y=train_y,\n",
    "    batch_size=50,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "fer_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=10000,\n",
    "    hooks=[logging_hook])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-06-01-02:00:02\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model\\model.ckpt-40000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-06-01-02:00:06\n",
      "INFO:tensorflow:Saving dict for global step 40000: accuracy = 0.5330176, global_step = 40000, loss = 1.7321916\n",
      "{'loss': 1.7321916, 'accuracy': 0.5330176, 'global_step': 40000}\n",
      "loss\n",
      "accuracy\n",
      "global_step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": val_x},\n",
    "    y=val_y,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_results = fer_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model\\model.ckpt-40000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "0\n",
      "0\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "2\n",
      "0\n",
      "6\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "6\n",
      "3\n",
      "4\n",
      "4\n",
      "0\n",
      "5\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "4\n",
      "2\n",
      "6\n",
      "0\n",
      "4\n",
      "0\n",
      "4\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "5\n",
      "4\n",
      "6\n",
      "0\n",
      "4\n",
      "5\n",
      "4\n",
      "0\n",
      "0\n",
      "2\n",
      "3\n",
      "5\n",
      "4\n",
      "0\n",
      "4\n",
      "0\n",
      "4\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "5\n",
      "6\n",
      "4\n",
      "4\n",
      "0\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "5\n",
      "4\n",
      "6\n",
      "5\n",
      "3\n",
      "6\n",
      "6\n",
      "5\n",
      "0\n",
      "5\n",
      "5\n",
      "6\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "0\n",
      "6\n",
      "2\n",
      "5\n",
      "2\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "0\n",
      "6\n",
      "6\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "0\n",
      "6\n",
      "5\n",
      "3\n",
      "6\n",
      "2\n",
      "2\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "6\n",
      "3\n",
      "6\n",
      "5\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "4\n",
      "5\n",
      "3\n",
      "6\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "6\n",
      "0\n",
      "3\n",
      "4\n",
      "0\n",
      "4\n",
      "2\n",
      "6\n",
      "6\n",
      "5\n",
      "4\n",
      "6\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "6\n",
      "3\n",
      "2\n",
      "5\n",
      "5\n",
      "0\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "3\n",
      "6\n",
      "4\n",
      "3\n",
      "5\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "5\n",
      "3\n",
      "0\n",
      "4\n",
      "6\n",
      "4\n",
      "2\n",
      "6\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "2\n",
      "6\n",
      "5\n",
      "1\n",
      "5\n",
      "3\n",
      "3\n",
      "6\n",
      "2\n",
      "6\n",
      "2\n",
      "3\n",
      "0\n",
      "6\n",
      "3\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "6\n",
      "0\n",
      "3\n",
      "6\n",
      "2\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "0\n",
      "6\n",
      "0\n",
      "3\n",
      "3\n",
      "4\n",
      "6\n",
      "6\n",
      "0\n",
      "2\n",
      "3\n",
      "3\n",
      "6\n",
      "4\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "2\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "4\n",
      "3\n",
      "3\n",
      "0\n",
      "6\n",
      "4\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "6\n",
      "4\n",
      "3\n",
      "6\n",
      "5\n",
      "0\n",
      "5\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "6\n",
      "3\n",
      "6\n",
      "0\n",
      "2\n",
      "3\n",
      "0\n",
      "3\n",
      "5\n",
      "4\n",
      "6\n",
      "5\n",
      "6\n",
      "2\n",
      "2\n",
      "4\n",
      "0\n",
      "6\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "3\n",
      "2\n",
      "0\n",
      "6\n",
      "5\n",
      "4\n",
      "6\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "0\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "6\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "6\n",
      "2\n",
      "6\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "2\n",
      "6\n",
      "3\n",
      "6\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "4\n",
      "3\n",
      "6\n",
      "6\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "0\n",
      "3\n",
      "3\n",
      "6\n",
      "4\n",
      "4\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "0\n",
      "4\n",
      "3\n",
      "6\n",
      "5\n",
      "2\n",
      "6\n",
      "6\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "6\n",
      "4\n",
      "3\n",
      "0\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "6\n",
      "3\n",
      "6\n",
      "3\n",
      "2\n",
      "3\n",
      "5\n",
      "6\n",
      "3\n",
      "3\n",
      "0\n",
      "5\n",
      "5\n",
      "3\n",
      "6\n",
      "6\n",
      "4\n",
      "5\n",
      "6\n",
      "6\n",
      "3\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "6\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "6\n",
      "3\n",
      "0\n",
      "5\n",
      "6\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "6\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "3\n",
      "6\n",
      "3\n",
      "2\n",
      "4\n",
      "6\n",
      "5\n",
      "2\n",
      "5\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "4\n",
      "3\n",
      "6\n",
      "3\n",
      "6\n",
      "3\n",
      "6\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "2\n",
      "6\n",
      "4\n",
      "4\n",
      "3\n",
      "6\n",
      "4\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "4\n",
      "6\n",
      "6\n",
      "3\n",
      "0\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "6\n",
      "6\n",
      "4\n",
      "0\n",
      "4\n",
      "3\n",
      "0\n",
      "4\n",
      "5\n",
      "4\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "6\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "0\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "0\n",
      "1\n",
      "3\n",
      "6\n",
      "0\n",
      "0\n",
      "3\n",
      "5\n",
      "4\n",
      "6\n",
      "6\n",
      "2\n",
      "3\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "6\n",
      "5\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "6\n",
      "4\n",
      "5\n",
      "6\n",
      "3\n",
      "5\n",
      "4\n",
      "0\n",
      "2\n",
      "0\n",
      "6\n",
      "5\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "0\n",
      "0\n",
      "6\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "3\n",
      "4\n",
      "6\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "6\n",
      "3\n",
      "0\n",
      "3\n",
      "2\n",
      "5\n",
      "3\n",
      "0\n",
      "6\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "2\n",
      "5\n",
      "5\n",
      "3\n",
      "2\n",
      "4\n",
      "6\n",
      "0\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "2\n",
      "3\n",
      "0\n",
      "6\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "5\n",
      "0\n",
      "0\n",
      "3\n",
      "5\n",
      "2\n",
      "5\n",
      "2\n",
      "4\n",
      "3\n",
      "6\n",
      "3\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "6\n",
      "4\n",
      "2\n",
      "6\n",
      "6\n",
      "5\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "0\n",
      "6\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "6\n",
      "2\n",
      "2\n",
      "3\n",
      "6\n",
      "6\n",
      "0\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "6\n",
      "5\n",
      "6\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "6\n",
      "0\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "2\n",
      "4\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "2\n",
      "5\n",
      "3\n",
      "2\n",
      "4\n",
      "6\n",
      "6\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "2\n",
      "6\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "0\n",
      "6\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "4\n",
      "3\n",
      "2\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "6\n",
      "0\n",
      "6\n",
      "4\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "0\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "6\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "5\n",
      "3\n",
      "3\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "5\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "6\n",
      "3\n",
      "6\n",
      "0\n",
      "6\n",
      "0\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "4\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "0\n",
      "6\n",
      "4\n",
      "0\n",
      "4\n",
      "2\n",
      "5\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "0\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "6\n",
      "3\n",
      "1\n",
      "6\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "3\n",
      "6\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "3\n",
      "0\n",
      "4\n",
      "6\n",
      "0\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "3\n",
      "2\n",
      "6\n",
      "0\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "6\n",
      "0\n",
      "3\n",
      "0\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "6\n",
      "0\n",
      "2\n",
      "5\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "6\n",
      "4\n",
      "2\n",
      "6\n",
      "5\n",
      "3\n",
      "4\n",
      "6\n",
      "5\n",
      "6\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "0\n",
      "5\n",
      "3\n",
      "1\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "0\n",
      "6\n",
      "4\n",
      "3\n",
      "5\n",
      "6\n",
      "3\n",
      "0\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "6\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "6\n",
      "6\n",
      "5\n",
      "2\n",
      "4\n",
      "0\n",
      "3\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "0\n",
      "6\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "0\n",
      "6\n",
      "3\n",
      "6\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "2\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "0\n",
      "3\n",
      "5\n",
      "2\n",
      "3\n",
      "3\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "6\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "5\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "6\n",
      "6\n",
      "3\n",
      "0\n",
      "4\n",
      "6\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "3\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "5\n",
      "5\n",
      "2\n",
      "3\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "3\n",
      "1\n",
      "4\n",
      "6\n",
      "5\n",
      "4\n",
      "0\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "2\n",
      "0\n",
      "2\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "6\n",
      "1\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "3\n",
      "0\n",
      "3\n",
      "4\n",
      "3\n",
      "6\n",
      "4\n",
      "0\n",
      "6\n",
      "0\n",
      "5\n",
      "5\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "3\n",
      "4\n",
      "0\n",
      "0\n",
      "5\n",
      "4\n",
      "2\n",
      "2\n",
      "6\n",
      "4\n",
      "0\n",
      "4\n",
      "3\n",
      "2\n",
      "6\n",
      "0\n",
      "2\n",
      "4\n",
      "0\n",
      "2\n",
      "4\n",
      "3\n",
      "6\n",
      "4\n",
      "0\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "6\n",
      "4\n",
      "4\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "6\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "5\n",
      "4\n",
      "6\n",
      "3\n",
      "0\n",
      "2\n",
      "5\n",
      "3\n",
      "1\n",
      "0\n",
      "6\n",
      "5\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "4\n",
      "3\n",
      "6\n",
      "3\n",
      "0\n",
      "4\n",
      "6\n",
      "4\n",
      "2\n",
      "0\n",
      "6\n",
      "3\n",
      "6\n",
      "2\n",
      "6\n",
      "3\n",
      "2\n",
      "0\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "6\n",
      "0\n",
      "6\n",
      "2\n",
      "6\n",
      "4\n",
      "6\n",
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "6\n",
      "0\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "5\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "6\n",
      "3\n",
      "6\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "0\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "0\n",
      "4\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "2\n",
      "6\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "6\n",
      "2\n",
      "4\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "1\n",
      "3\n",
      "6\n",
      "4\n",
      "4\n",
      "5\n",
      "6\n",
      "2\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "0\n",
      "3\n",
      "0\n",
      "6\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "6\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "6\n",
      "3\n",
      "6\n",
      "0\n",
      "5\n",
      "3\n",
      "6\n",
      "0\n",
      "0\n",
      "4\n",
      "6\n",
      "5\n",
      "6\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "1\n",
      "4\n",
      "6\n",
      "2\n",
      "6\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "3\n",
      "6\n",
      "2\n",
      "6\n",
      "5\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "5\n",
      "6\n",
      "3\n",
      "3\n",
      "5\n",
      "6\n",
      "4\n",
      "3\n",
      "0\n",
      "2\n",
      "4\n",
      "5\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "4\n",
      "6\n",
      "4\n",
      "3\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "6\n",
      "0\n",
      "0\n",
      "4\n",
      "3\n",
      "6\n",
      "4\n",
      "3\n",
      "6\n",
      "2\n",
      "6\n",
      "3\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "6\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "3\n",
      "6\n",
      "2\n",
      "2\n",
      "6\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "5\n",
      "0\n",
      "3\n",
      "2\n",
      "0\n",
      "0\n",
      "6\n",
      "1\n",
      "3\n",
      "6\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "6\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "6\n",
      "1\n",
      "4\n",
      "5\n",
      "0\n",
      "3\n",
      "6\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "5\n",
      "3\n",
      "3\n",
      "6\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "5\n",
      "6\n",
      "0\n",
      "0\n",
      "3\n",
      "2\n",
      "0\n",
      "6\n",
      "2\n",
      "5\n",
      "2\n",
      "3\n",
      "0\n",
      "3\n",
      "5\n",
      "6\n",
      "6\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "5\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "6\n",
      "0\n",
      "5\n",
      "3\n",
      "2\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "6\n",
      "2\n",
      "0\n",
      "5\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "6\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "6\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "2\n",
      "6\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "3\n",
      "6\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "6\n",
      "5\n",
      "2\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "1\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "0\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "0\n",
      "2\n",
      "5\n",
      "6\n",
      "6\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "0\n",
      "6\n",
      "3\n",
      "6\n",
      "3\n",
      "4\n",
      "4\n",
      "6\n",
      "0\n",
      "6\n",
      "6\n",
      "3\n",
      "2\n",
      "6\n",
      "5\n",
      "3\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n",
      "6\n",
      "5\n",
      "0\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "6\n",
      "4\n",
      "0\n",
      "0\n",
      "6\n",
      "3\n",
      "2\n",
      "3\n",
      "6\n",
      "0\n",
      "5\n",
      "3\n",
      "2\n",
      "6\n",
      "2\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "4\n",
      "2\n",
      "5\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "0\n",
      "5\n",
      "0\n",
      "5\n",
      "0\n",
      "4\n",
      "2\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "5\n",
      "0\n",
      "2\n",
      "4\n",
      "4\n",
      "6\n",
      "1\n",
      "0\n",
      "3\n",
      "4\n",
      "3\n",
      "1\n",
      "2\n",
      "6\n",
      "5\n",
      "4\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "2\n",
      "3\n",
      "5\n",
      "4\n",
      "6\n",
      "2\n",
      "4\n",
      "5\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "6\n",
      "4\n",
      "5\n",
      "6\n",
      "4\n",
      "0\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "5\n",
      "4\n",
      "2\n",
      "3\n",
      "6\n",
      "3\n",
      "2\n",
      "0\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "2\n",
      "6\n",
      "4\n",
      "3\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "6\n",
      "4\n",
      "0\n",
      "4\n",
      "6\n",
      "2\n",
      "6\n",
      "4\n",
      "6\n",
      "5\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "0\n",
      "5\n",
      "4\n",
      "5\n",
      "6\n",
      "3\n",
      "3\n",
      "0\n",
      "2\n",
      "2\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "0\n",
      "6\n",
      "5\n",
      "6\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "3\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "3\n",
      "3\n",
      "6\n",
      "0\n",
      "4\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "2\n",
      "6\n",
      "6\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "3\n",
      "0\n",
      "6\n",
      "6\n",
      "5\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "6\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "6\n",
      "4\n",
      "2\n",
      "3\n",
      "6\n",
      "1\n",
      "2\n",
      "2\n",
      "4\n",
      "0\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "0\n",
      "4\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "4\n",
      "5\n",
      "3\n",
      "0\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "6\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "0\n",
      "2\n",
      "4\n",
      "3\n",
      "5\n",
      "0\n",
      "3\n",
      "6\n",
      "6\n",
      "0\n",
      "2\n",
      "5\n",
      "0\n",
      "4\n",
      "4\n",
      "6\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "5\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "6\n",
      "2\n",
      "2\n",
      "2\n",
      "6\n",
      "0\n",
      "6\n",
      "6\n",
      "2\n",
      "6\n",
      "6\n",
      "3\n",
      "2\n",
      "3\n",
      "6\n",
      "3\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "5\n",
      "2\n",
      "4\n",
      "5\n",
      "2\n",
      "6\n",
      "6\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "6\n",
      "6\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "6\n",
      "0\n",
      "3\n",
      "0\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "0\n",
      "1\n",
      "6\n",
      "5\n",
      "5\n",
      "2\n",
      "0\n",
      "6\n",
      "3\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "6\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "0\n",
      "2\n",
      "5\n",
      "6\n",
      "6\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "2\n",
      "3\n",
      "0\n",
      "3\n",
      "2\n",
      "0\n",
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "6\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "2\n",
      "3\n",
      "6\n",
      "6\n",
      "0\n",
      "0\n",
      "3\n",
      "5\n",
      "5\n",
      "6\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "6\n",
      "3\n",
      "0\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "6\n",
      "4\n",
      "1\n",
      "6\n",
      "0\n",
      "6\n",
      "6\n",
      "0\n",
      "0\n",
      "5\n",
      "2\n",
      "3\n",
      "0\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "6\n",
      "3\n",
      "4\n",
      "6\n",
      "0\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "4\n",
      "0\n",
      "2\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "0\n",
      "4\n",
      "5\n",
      "4\n",
      "6\n",
      "3\n",
      "2\n",
      "5\n",
      "3\n",
      "6\n",
      "0\n",
      "4\n",
      "3\n",
      "2\n",
      "0\n",
      "0\n",
      "3\n",
      "2\n",
      "5\n",
      "6\n",
      "3\n",
      "5\n",
      "3\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "5\n",
      "0\n",
      "3\n",
      "3\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "5\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "0\n",
      "1\n",
      "4\n",
      "6\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "6\n",
      "3\n",
      "6\n",
      "5\n",
      "3\n",
      "6\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "5\n",
      "0\n",
      "3\n",
      "1\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "3\n",
      "6\n",
      "5\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "5\n",
      "0\n",
      "4\n",
      "6\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "5\n",
      "5\n",
      "2\n",
      "3\n",
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "3\n",
      "6\n",
      "4\n",
      "3\n",
      "3\n",
      "0\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "6\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "6\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "6\n",
      "4\n",
      "3\n",
      "6\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "6\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "0\n",
      "4\n",
      "5\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "2\n",
      "6\n",
      "3\n",
      "4\n",
      "3\n",
      "0\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "6\n",
      "2\n",
      "5\n",
      "0\n",
      "6\n",
      "4\n",
      "3\n",
      "6\n",
      "5\n",
      "0\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "2\n",
      "0\n",
      "3\n",
      "6\n",
      "5\n",
      "6\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "6\n",
      "2\n",
      "5\n",
      "5\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "4\n",
      "6\n",
      "6\n",
      "4\n",
      "5\n",
      "0\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "0\n",
      "5\n",
      "5\n",
      "1\n",
      "5\n",
      "5\n",
      "3\n",
      "6\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "3\n",
      "6\n",
      "4\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "4\n",
      "6\n",
      "3\n",
      "4\n",
      "3\n",
      "0\n",
      "2\n",
      "3\n",
      "5\n",
      "5\n",
      "4\n",
      "6\n",
      "5\n",
      "0\n",
      "6\n",
      "6\n",
      "4\n",
      "3\n",
      "0\n",
      "6\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "6\n",
      "0\n",
      "3\n",
      "3\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "0\n",
      "4\n",
      "6\n",
      "1\n",
      "3\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "6\n",
      "6\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "0\n",
      "2\n",
      "6\n",
      "2\n",
      "0\n",
      "0\n",
      "6\n",
      "3\n",
      "5\n",
      "6\n",
      "2\n",
      "6\n",
      "0\n",
      "0\n",
      "3\n",
      "2\n",
      "2\n",
      "0\n",
      "4\n",
      "6\n",
      "0\n",
      "5\n",
      "3\n",
      "6\n",
      "4\n",
      "6\n",
      "3\n",
      "2\n",
      "0\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "0\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "5\n",
      "6\n",
      "0\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "0\n",
      "0\n",
      "5\n",
      "5\n",
      "3\n",
      "2\n",
      "4\n",
      "0\n",
      "6\n",
      "4\n",
      "6\n",
      "0\n",
      "6\n",
      "4\n",
      "6\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "6\n",
      "6\n",
      "0\n",
      "0\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "1\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "0\n",
      "6\n",
      "5\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "5\n",
      "0\n",
      "4\n",
      "3\n",
      "3\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "3\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "5\n",
      "3\n",
      "5\n",
      "6\n",
      "6\n",
      "3\n",
      "0\n",
      "3\n",
      "6\n",
      "0\n",
      "0\n",
      "3\n",
      "5\n",
      "4\n",
      "6\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "6\n",
      "2\n",
      "2\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "5\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "0\n",
      "6\n",
      "4\n",
      "2\n",
      "6\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "6\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "2\n",
      "6\n",
      "5\n",
      "4\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "0\n",
      "5\n",
      "5\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "6\n",
      "5\n",
      "0\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "4\n",
      "3\n",
      "6\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "5\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "6\n",
      "6\n",
      "5\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "1\n",
      "6\n",
      "2\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "6\n",
      "3\n",
      "0\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "4\n",
      "0\n",
      "3\n",
      "6\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "0\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "6\n",
      "5\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "3\n",
      "0\n",
      "2\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "0\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "0\n",
      "6\n",
      "5\n",
      "2\n",
      "3\n",
      "6\n",
      "6\n",
      "5\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "1\n",
      "6\n",
      "0\n",
      "2\n",
      "6\n",
      "4\n",
      "3\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "2\n",
      "5\n",
      "0\n",
      "4\n",
      "4\n",
      "0\n",
      "6\n",
      "0\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "6\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "4\n",
      "6\n",
      "0\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "6\n",
      "6\n",
      "0\n",
      "3\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "3\n",
      "4\n",
      "6\n",
      "3\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "4\n",
      "0\n",
      "6\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "0\n",
      "3\n",
      "5\n",
      "4\n",
      "0\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "6\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "0\n",
      "6\n",
      "2\n",
      "0\n",
      "3\n",
      "4\n",
      "3\n",
      "6\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "2\n",
      "5\n",
      "0\n",
      "0\n",
      "3\n",
      "4\n",
      "6\n",
      "5\n",
      "4\n",
      "0\n",
      "0\n",
      "4\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "0\n",
      "6\n",
      "3\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "4\n",
      "6\n",
      "3\n",
      "6\n",
      "3\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "3\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "0\n",
      "4\n",
      "2\n",
      "5\n",
      "4\n",
      "6\n",
      "6\n",
      "2\n",
      "4\n",
      "1\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "4\n",
      "1\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "4\n",
      "0\n",
      "2\n",
      "3\n",
      "2\n",
      "6\n",
      "6\n",
      "0\n",
      "4\n",
      "3\n",
      "0\n",
      "3\n",
      "6\n",
      "3\n",
      "2\n",
      "2\n",
      "6\n",
      "2\n",
      "0\n",
      "0\n",
      "6\n",
      "2\n",
      "5\n",
      "6\n",
      "0\n",
      "3\n",
      "6\n",
      "3\n",
      "6\n",
      "2\n",
      "2\n",
      "6\n",
      "6\n",
      "0\n",
      "4\n",
      "3\n",
      "5\n",
      "6\n",
      "0\n",
      "6\n",
      "6\n",
      "3\n",
      "6\n",
      "5\n",
      "3\n",
      "0\n",
      "3\n",
      "2\n",
      "0\n",
      "0\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "4\n",
      "6\n",
      "6\n",
      "2\n",
      "2\n",
      "6\n",
      "6\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "6\n",
      "6\n",
      "0\n",
      "0\n",
      "2\n",
      "5\n",
      "6\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "0\n",
      "6\n",
      "0\n",
      "6\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "2\n",
      "0\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "6\n",
      "2\n",
      "0\n",
      "6\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "6\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "0\n",
      "2\n",
      "6\n",
      "0\n",
      "4\n",
      "2\n",
      "0\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "6\n",
      "6\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "6\n",
      "6\n",
      "0\n",
      "2\n",
      "5\n",
      "6\n",
      "2\n",
      "0\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "6\n",
      "0\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "0\n",
      "0\n",
      "6\n",
      "0\n",
      "6\n",
      "0\n",
      "6\n",
      "2\n",
      "0\n",
      "3\n",
      "6\n",
      "0\n",
      "5\n",
      "1\n",
      "4\n",
      "3\n",
      "6\n",
      "5\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "0\n",
      "5\n",
      "6\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "6\n",
      "3\n",
      "2\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "3\n",
      "4\n",
      "3\n",
      "0\n",
      "4\n",
      "6\n",
      "0\n",
      "6\n",
      "2\n",
      "5\n",
      "0\n",
      "0\n",
      "2\n",
      "6\n",
      "6\n",
      "5\n",
      "2\n",
      "2\n",
      "4\n",
      "5\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "0\n",
      "2\n",
      "6\n",
      "3\n",
      "3\n",
      "0\n",
      "6\n",
      "3\n",
      "6\n",
      "0\n",
      "3\n",
      "6\n",
      "6\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "6\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "6\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": val_x},\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "predict_results = fer_classifier.predict(input_fn=eval_input_fn)\n",
    "\n",
    "for i in predict_results:\n",
    "    print(np.argmax(i['probabilities']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(,input_fn,top_n):\n",
    "    # Set up logging for predictions\n",
    "    # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "    logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=500)\n",
    "    predict_results = fer_classifier.predict(input_fn=input_fn)\n",
    "    return predict_results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
